
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Pretrain from Scratch, Continue Training from an Existing Checkpoint, and Fine-tune ESM-2nv on Custom Data &#8212; NVIDIA BioNeMo Framework</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="https://js.hcaptcha.com/1/api.js"></script>
    <script src="//assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script src="../_static/design-tabs.js"></script>
    <link rel="canonical" href="https://docs.nvidia.com/bionemo-framework/0.4.0/notebooks/esm2_paratope_finetuning.html" />
    <link rel="shortcut icon" href="../_static/nvidia-logo-vert-rgb-blk-for-screen.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Generating and visualizing embeddings with DNABert" href="dnabert_inference.html" />
    <link rel="prev" title="Performing inference on OAS sequences with ESM-2nv" href="esm2_oas_inferencing.html" /> 
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
      
<style type="text/css">
  ul.ablog-archive {
    list-style: none;
    overflow: auto;
    margin-left: 0px;
  }
  ul.ablog-archive li {
    float: left;
    margin-right: 5px;
    font-size: 80%;
  }
  ul.postlist a {
    font-style: italic;
  }
  ul.postlist-style-disc {
    list-style-type: disc;
  }
  ul.postlist-style-none {
    list-style-type: none;
  }
  ul.postlist-style-circle {
    list-style-type: circle;
  }
</style>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/nvidia-logo-horiz-rgb-blk-for-screen.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">NVIDIA BioNeMo Framework</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  GETTING STARTED
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   What is BioNeMo?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pre-reqs.html">
   Hardware and Software Prerequisites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../access-startup.html">
   Access and Startup
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../initialization-guide.html">
   Initialization Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorial-list.html">
   BioNeMo Framework Tutorials
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  BioNeMo CORE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../bionemo-fw-for-model-training-fw.html">
   Fundamentals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-module-fw.html">
   Data Module
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dwnstr-task-validation.html">
   Validation with a Downstream Task
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../inference-triton-fw.html">
   Inference with Nvidia Triton Server
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-dive-esm1-pytriton-inference.html">
   Example of PyTriton Inference
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  BEST PRACTICES
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../hyperparameters-fw.html">
   Hyperparameter Usage and Tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../parallelism-fw.html">
   Training Parallelism
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MODELS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../models/diffdock.html">
   DiffDock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/dnabert.html">
   DNABERT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/dsmbind.html">
   DSMBind
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/equidock.html">
   EquiDock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/esm1-nv.html">
   ESM-1nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/esm2-nv.html">
   ESM-2nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/geneformer.html">
   Geneformer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/megamolbart.html">
   MegaMolBART
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/molmim.html">
   MolMIM
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/openfold.html">
   OpenFold
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/prott5nv.html">
   Prott5nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/model-benchmarks.html">
   Model Benchmarks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DATASETS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/uniprot.html">
   UniProt Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/CELLxGENE.html">
   CELLxGENE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/zinc15.html">
   ZINC-15 Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/pdb.html">
   The Protein Data Bank (PDB)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/GRCh38.p13.html">
   Human Reference Genome Version GRCh38.p13
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/openproteinset.html">
   OpenProteinSet
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/moleculenet-physchem.html">
   MoleculeNet Physical Chemistry Datasets - Lipophilicity, FreeSolv, ESOL
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  TUTORIALS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../preprocessing-bcp-training-diffdock.html">
   DiffDock: Preparing Workspace and Data for Pre-training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="esm2nv-mutant-design.html">
   Zero-Shot Protein Design Using ESM-2nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MMB_GenerativeAI_Inference_with_examples.html">
   BioNeMo - MegaMolBART Inferencing for Generative Chemistry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MolMIM_GenerativeAI_local_inference_with_examples.html">
   MolMIM Inferencing for Generative Chemistry and Downstream Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ZINC15-data-preprocessing.html">
   ZINC Training Dataset Setup for small molecule language models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bionemo-finetuning-overview.html">
   Finetune pre-trained models in BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cma_es_guided_molecular_optimization_molmim.html">
   MolMIM Property Guided Molecular Optimization Using CMA-ES
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="custom-dataset-class-fw.html">
   Adding the OAS Dataset: Modifying the Dataset Class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="custom-dataset-dataloader.html">
   Adding the OAS Dataset: Customizing Dataset Object and Dataloader Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="custom-dataset-preprocessing-fw.html">
   Adding the OAS Dataset: Downloading and Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="encoder-finetuning-notebook-fw.html">
   Encoder Fine-tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_diffdock.html">
   DiffDock Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_equidock.html">
   EquiDock Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_esm1nv.html">
   ESM1nv Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_esm2nv.html">
   ESM-2nv: Data Preprocessing and Model Training Using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_mmb.html">
   MegaMolBART Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_molmim.html">
   Train MolMIM from scratch on your own data using the BioNeMo Framework
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="physchem-notebook-fw.html">
   Finetuning LLM in BioNeMo for a Downstream Task
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="protein-esm2nv-clustering.html">
   Generating Embeddings for Protein Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="retrosynthesis-notebook.html">
   Training LLM for a Custom Downstram Task: Retrosynthesis Prediction using MegaMolBART
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="esm2_FLIP_finetuning.html">
   Fine-Tune ESM-2nv on FLIP Data for Sequence-Level Classification, Regression, Token-Level Classification, and with LoRA Adapters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="esm2_oas_inferencing.html">
   Performing inference on OAS sequences with ESM-2nv
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Pretrain from Scratch, Continue Training from an Existing Checkpoint, and Fine-tune ESM-2nv on Custom Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dnabert_inference.html">
   Generating and visualizing embeddings with DNABert
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dnabert_pretrain_finetune.html">
   Pretrain, Fine-tune, and Perform Inference with DNABERT for Splice Site Prediction
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  APPENDIX
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../faq-fw.html">
   Frequently Asked Questions (FAQ)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bibliography-fw.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../releasenotes-fw.html">
   Release Notes
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#demo-objectives">
   Demo Objectives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-and-install-all-required-packages">
   Import and install all required packages
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#home-directory">
   Home Directory
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-download-and-preprocessing">
   Data Download and Preprocessing
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#download-model-checkpoints">
   Download Model Checkpoints
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing-and-pretraining-from-scratch">
   Preprocessing and Pretraining from Scratch
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pretrain-from-scratch">
     Pretrain from scratch
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#continue-pretraining-add-a-downstream-head-perform-full-parameter-fine-tuning-for-esm-2nv-on-antibody-sequences">
   Continue Pretraining, Add a Downstream Head, Perform Full Parameter Fine-Tuning for ESM-2nv on Antibody Sequences
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#continue-training-from-a-model-checkpoint">
     1. Continue training from a model checkpoint
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#downstream-head-fine-tuning">
     2. Downstream Head Fine-Tuning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#full-parameter-fine-tuning">
     3. Full Parameter Fine-Tuning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#low-rank-adaptation-lora-fine-tuning">
     4. Low-Rank Adaptation (LoRA) fine-tuning
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Pretrain from Scratch, Continue Training from an Existing Checkpoint, and Fine-tune ESM-2nv on Custom Data</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#demo-objectives">
   Demo Objectives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-and-install-all-required-packages">
   Import and install all required packages
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#home-directory">
   Home Directory
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-download-and-preprocessing">
   Data Download and Preprocessing
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#download-model-checkpoints">
   Download Model Checkpoints
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing-and-pretraining-from-scratch">
   Preprocessing and Pretraining from Scratch
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pretrain-from-scratch">
     Pretrain from scratch
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#continue-pretraining-add-a-downstream-head-perform-full-parameter-fine-tuning-for-esm-2nv-on-antibody-sequences">
   Continue Pretraining, Add a Downstream Head, Perform Full Parameter Fine-Tuning for ESM-2nv on Antibody Sequences
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#continue-training-from-a-model-checkpoint">
     1. Continue training from a model checkpoint
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#downstream-head-fine-tuning">
     2. Downstream Head Fine-Tuning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#full-parameter-fine-tuning">
     3. Full Parameter Fine-Tuning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#low-rank-adaptation-lora-fine-tuning">
     4. Low-Rank Adaptation (LoRA) fine-tuning
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                 <div class="tex2jax_ignore mathjax_ignore section" id="pretrain-from-scratch-continue-training-from-an-existing-checkpoint-and-fine-tune-esm-2nv-on-custom-data">
<h1>Pretrain from Scratch, Continue Training from an Existing Checkpoint, and Fine-tune ESM-2nv on Custom Data<a class="headerlink" href="#pretrain-from-scratch-continue-training-from-an-existing-checkpoint-and-fine-tune-esm-2nv-on-custom-data" title="Permalink to this headline">#</a></h1>
<div class="alert alert-block alert-info"> <b>NOTE</b> This notebook was tested on a single A1000 GPU and is compatible with BioNeMo Framework v1.6, v1.7 and v1.8 with an expected runtime of approximately 2 hours for ESM-2nv 650M model. This notebook is specific to the ESM-2nv model only. </div>
<div class="section" id="demo-objectives">
<h2>Demo Objectives<a class="headerlink" href="#demo-objectives" title="Permalink to this headline">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Continue Training from a Model Checkpoint</strong></p>
<ul class="simple">
<li><p><strong>Objective:</strong> Utilize ESM-2nv models for predicting antibody function with an additional prediction headâ€¦</p></li>
<li><p><strong>Steps:</strong> Collect the data, and use existing downstream prediction head training scripts in BioNeMo for token-level classification.</p></li>
</ul>
</li>
<li><p><strong>Downstream Head Fine-tuning</strong></p>
<ul class="simple">
<li><p><strong>Objective:</strong> Fine-tune ESM-2nv for predicting antibody function with an additional prediction head.</p></li>
<li><p><strong>Steps:</strong> Collect the data, and use existing downstream prediction head training scripts in BioNeMo for token-level classification.</p></li>
</ul>
</li>
<li><p><strong>Full Parameter Fine-tuning on Antibody Sequences</strong></p>
<ul class="simple">
<li><p><strong>Objective:</strong> Fine-tune an ESM-2nv foundation model and head on antibody sequences to enhance recognition of specific sequence patterns.</p></li>
<li><p><strong>Steps:</strong> Prepare dataset, and fine-tune ESM-2nv.</p></li>
</ul>
</li>
<li><p><strong>Low-Rank Adaptation (LoRA) Fine-tuning</strong></p>
<ul class="simple">
<li><p><strong>Objective:</strong> Apply LoRA to ESM-2nv for antibody sequences to improve efficiency and robustness.</p></li>
<li><p><strong>Steps:</strong> Integrate LoRA adapters, and fine-tune adapters while freezing core weights.</p></li>
</ul>
</li>
</ol>
<p>For this purpose, we will use data available from the <a class="reference external" href="https://tdcommons.ai/">Therapeutic Data Commons</a> for the prediction of amino acid binding in antibody sequences.</p>
</div>
<div class="section" id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">#</a></h2>
<p>Ensure that you have read through the <a class="reference internal" href="../index.html"><span class="doc std std-doc">Getting Started</span></a> section, can run the BioNeMo Framework Docker container, and have configured the NGC Command Line Interface (CLI) within the container. It is assumed that this notebook is being executed from within the container.</p>
<div class="alert alert-block alert-info"> <b>NOTE</b> Some of the cells below generate long text output.  We're using <pre>%%capture --no-display --no-stderr cell_output</pre> to suppress this output.  Comment or delete this line in the cells below to restore full output.</div>
</div>
<div class="section" id="import-and-install-all-required-packages">
<h2>Import and install all required packages<a class="headerlink" href="#import-and-install-all-required-packages" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%%capture --no-display --no-stderr cell_output
! pip install PyTDC

import os
import pandas as pd
import warnings

# Importing libraries to download and split datasets from the Therapeutic Data Commons https://tdcommons.ai/
from tdc.single_pred import Paratope

warnings.filterwarnings(&#39;ignore&#39;)
warnings.simplefilter(&#39;ignore&#39;)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="home-directory">
<h2>Home Directory<a class="headerlink" href="#home-directory" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bionemo_home</span> <span class="o">=</span> <span class="s2">&quot;/workspace/bionemo&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;BIONEMO_HOME&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bionemo_home</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">bionemo_home</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="data-download-and-preprocessing">
<h2>Data Download and Preprocessing<a class="headerlink" href="#data-download-and-preprocessing" title="Permalink to this headline">#</a></h2>
<p><strong>Dataset Overview</strong>: This dataset focuses on paratope prediction, which involves identifying the active binding regions within an antibody. It compiles sequences from SAbDab, encompassing both the heavy and light chains of the antibody.</p>
<p><strong>Objective</strong>: The task involves classifying at the token level. For a given sequence of amino acids, the goal is to identify the specific amino acid tokens that are active in binding. In this context, <code class="docutils literal notranslate"><span class="pre">X</span></code> represents the amino acid sequence, while <code class="docutils literal notranslate"><span class="pre">Y</span></code> denotes the indices of active binding positions within <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p>
<p><strong>Dataset Details</strong>: The dataset comprises sequences from 1,023 antibody chains.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Specify dataset for download</span>
<span class="n">dataset_name</span> <span class="o">=</span> <span class="s1">&#39;SAbDab_Liberis&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Preparing raw </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> dataset from TD Commons.&quot;</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">Paratope</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="n">dataset_name</span><span class="p">)</span>
<span class="n">data_df</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span>
<span class="n">splits</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">get_split</span><span class="p">()</span>
<span class="n">data_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Found local copy...
Loading...
Done!
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Preparing raw SAbDab_Liberis dataset from TD Commons.
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Antibody_ID</th>
      <th>Antibody</th>
      <th>Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2hh0_H</td>
      <td>LEQSGAELVKPGASVKLSCTASGFNIEDSYIHWVKQRPEQGLEWIG...</td>
      <td>[49, 80, 81, 82, 101]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1u8q_B</td>
      <td>ITLKESGPPLVKPTQTLTLTCSFSGFSLSDFGVGVGWIRQPPGKAL...</td>
      <td>[30, 31, 53, 83, 84, 85, 104, 105, 106, 107, 1...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4ydl_H</td>
      <td>EVRLVQSGNQVRKPGASVRISCEASGYKFIDHFIHWVRQVPGHGLE...</td>
      <td>[52, 67, 68, 85, 86, 87, 106, 107]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4ydl_L</td>
      <td>EIVLTQSPGTLSLSPGETATLSCRTSQGILSNQLAWHQQRRGQPPR...</td>
      <td>[30]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1mhp_X</td>
      <td>EVQLVESGGGLVQPGGSLRLSCAASGFTFSRYTMSWVRQAPGKGLE...</td>
      <td>[52, 82, 83, 84, 103, 104]</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Each antibody sequence (<code class="docutils literal notranslate"><span class="pre">Antibody</span></code>) is a string of amino acids, where the order and composition determine its function and specificity. Within each antibody sequence, specific positions (<code class="docutils literal notranslate"><span class="pre">Y</span></code>) are crucial for its function and denote their belonging to the paratope of the antibody. Here, we define a function (<code class="docutils literal notranslate"><span class="pre">encode_sequence</span></code>) to encode these specific positions in the antibody sequence by initializing a sequence with placeholders (<code class="docutils literal notranslate"><span class="pre">N</span></code> for non-paratope positions) and marking the positions of interest with a label <code class="docutils literal notranslate"><span class="pre">P</span></code>, denoting amino acids that belong to the paratope. The dataset is then divided into subsets (<code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">val</span></code>, <code class="docutils literal notranslate"><span class="pre">test</span></code>), and each subset undergoes the encoding strategy.</p>
<p>For ESM-2 to be trained on custom sequences, we will also need to create FASTA files.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">base_data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">bionemo_home</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">)</span>
<span class="n">task_name</span> <span class="o">=</span> <span class="s2">&quot;paratope&quot;</span>
<span class="o">!</span>mkdir<span class="w"> </span>-p<span class="w"> </span><span class="o">{</span>base_data_dir<span class="o">}</span>/processed/<span class="o">{</span>dataset_name<span class="o">}</span>

<span class="n">SAbDab_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_data_dir</span><span class="p">,</span> <span class="s1">&#39;processed&#39;</span><span class="p">,</span> <span class="n">dataset_name</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">encode_sequence</span><span class="p">(</span><span class="n">row</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">sequence</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="s1">&#39;N&#39;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;Antibody&#39;</span><span class="p">]))</span>  <span class="c1"># Create a list of &#39;N&#39;s the same length as the sequence</span>
    <span class="c1"># Check if row[&#39;Y&#39;] is a string that needs to be evaluated</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">],</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">positions</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>  <span class="c1"># Convert string representation of list to actual list</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">positions</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">]</span>  <span class="c1"># Assume row[&#39;Y&#39;] is already in the correct format (e.g., a list)</span>
    <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="n">positions</span><span class="p">:</span>
        <span class="n">adj_pos</span> <span class="o">=</span> <span class="n">pos</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># Adjust the position to 0-based indexing</span>
        <span class="n">sequence</span><span class="p">[</span><span class="n">adj_pos</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;P&#39;</span>  <span class="c1"># Encode the position as &#39;P&#39;</span>
    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>  <span class="c1"># Convert the list back to a string</span>

<span class="c1"># List of split names, assuming they are &#39;train&#39;, &#39;valid&#39;, and &#39;test&#39;</span>
<span class="c1"># Update &#39;valid&#39; to &#39;val&#39; for the folder name</span>
<span class="n">split_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">split_name</span> <span class="ow">in</span> <span class="n">split_names</span><span class="p">:</span>
    <span class="c1"># Adjust the key for accessing the validation split if necessary</span>
    <span class="n">split_key</span> <span class="o">=</span> <span class="s1">&#39;valid&#39;</span> <span class="k">if</span> <span class="n">split_name</span> <span class="o">==</span> <span class="s1">&#39;val&#39;</span> <span class="k">else</span> <span class="n">split_name</span>
    <span class="c1"># Construct the file path</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">splits</span><span class="p">[</span><span class="n">split_key</span><span class="p">]</span>
    <span class="c1"># Apply the function to each row</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Encoded&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">encode_sequence</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Adjust the directory structure for saving, now including the task_name</span>
    <span class="n">task_specific_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">SAbDab_dir</span><span class="p">,</span> <span class="n">task_name</span><span class="p">,</span> <span class="n">split_name</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">task_specific_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Ensure the directory exists</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;Antibody&#39;</span><span class="p">,</span> <span class="s1">&#39;Encoded&#39;</span><span class="p">]]</span>  <span class="c1"># Reorder the columns</span>
    <span class="c1"># Save the modified DataFrame to the new path</span>
    <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">task_specific_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;x000.csv&quot;</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Encoded sequences saved as x000.csv in </span><span class="si">{</span><span class="n">task_specific_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Save as FASTA</span>
    <span class="n">fasta_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">task_specific_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;x000.fasta&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fasta_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fasta_file</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
            <span class="n">fasta_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&gt;Sequence_</span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;Antibody&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Encoded sequences saved as x000.fasta in </span><span class="si">{</span><span class="n">task_specific_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Encoded sequences saved as x000.csv in /workspace/bionemo/data/processed/SAbDab_Liberis/paratope/train
Encoded sequences saved as x000.fasta in /workspace/bionemo/data/processed/SAbDab_Liberis/paratope/train
Encoded sequences saved as x000.csv in /workspace/bionemo/data/processed/SAbDab_Liberis/paratope/val
Encoded sequences saved as x000.fasta in /workspace/bionemo/data/processed/SAbDab_Liberis/paratope/val
Encoded sequences saved as x000.csv in /workspace/bionemo/data/processed/SAbDab_Liberis/paratope/test
Encoded sequences saved as x000.fasta in /workspace/bionemo/data/processed/SAbDab_Liberis/paratope/test
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encoded_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">SAbDab_dir</span><span class="p">,</span> <span class="n">task_name</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;x000.csv&#39;</span><span class="p">))</span>
<span class="n">encoded_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Antibody</th>
      <th>Encoded</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>LEQSGAELVKPGASVKLSCTASGFNIEDSYIHWVKQRPEQGLEWIG...</td>
      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ITLKESGPPLVKPTQTLTLTCSFSGFSLSDFGVGVGWIRQPPGKAL...</td>
      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNPPNNNNNNNNNNNNNNN...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>EVRLVQSGNQVRKPGASVRISCEASGYKFIDHFIHWVRQVPGHGLE...</td>
      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>EVQLSESGGGFVKPGGSLRLSCEASGFTFNNYAMGWVRQAPGKGLE...</td>
      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>QVQLVQPGTAMKSLGSSLTITCRVSGDDLGSFHFGTYFMIWVRQAP...</td>
      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNPPPPPNNNNNNNNNNN...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="download-model-checkpoints">
<h2>Download Model Checkpoints<a class="headerlink" href="#download-model-checkpoints" title="Permalink to this headline">#</a></h2>
<p>The following code will download the pretrained model <code class="docutils literal notranslate"><span class="pre">esmn2nv_650M_converted.nemo</span></code> from the NGC registry.</p>
<p>In BioNeMo FW, there are numerous ESM models available, including ESM-1nv, ESM-2nv 8M with randomly initialized weights, ESM-2nv fine-tuned for secondary structure downstream prediction tasks with LoRA, ESM-2nv 650M, and ESM-2nv 3B. We also have a configuration file for training ESM-2nv 15B available at <code class="docutils literal notranslate"><span class="pre">examples/protein/esm2nv/conf/pretrain_esm2_15B.yaml</span></code>, if needed.</p>
<p>For demo purposes, we have chosen to showcase the ESM-2nv 650M model. For more details on the <a class="reference external" href="https://docs.nvidia.com/bionemo-framework/latest/models/esm1-nv.html">ESM-1nv</a> or <a class="reference external" href="https://docs.nvidia.com/bionemo-framework/latest/models/esm2-nv.html">ESM-2nv</a>, consult the corresponding model cards. To find the model names and checkpoint names please refer to the <code class="docutils literal notranslate"><span class="pre">artifacts_paths.yaml</span></code> file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the NGC CLI API KEY and ORG for the model download</span>
<span class="c1"># If these variables are not already set in the container, uncomment below</span>
<span class="c1"># to define and set with your API KEY and ORG</span>
<span class="c1"># api_key = &lt;YOUR_API_KEY&gt;</span>
<span class="c1"># ngc_cli_org = &lt;YOUR_ORG&gt;</span>
<span class="c1"># Update the environment variable</span>
<span class="c1"># os.environ[&#39;NGC_CLI_API_KEY&#39;] = api_key</span>
<span class="c1"># os.environ[&#39;NGC_CLI_ORG&#39;] = ngc_cli_org</span>

<span class="c1"># Set variables and paths for model and checkpoint</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;esm2nv&quot;</span> 
<span class="n">model_version</span> <span class="o">=</span> <span class="s2">&quot;esm2nv_650m&quot;</span> 
<span class="n">actual_checkpoint_name</span> <span class="o">=</span> <span class="s2">&quot;esm2nv_650M_converted.nemo&quot;</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">bionemo_home</span><span class="p">,</span> <span class="s1">&#39;models&#39;</span><span class="p">)</span>
<span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">actual_checkpoint_name</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MODEL_PATH&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_path</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%%capture --no-display --no-stderr cell_output
if not os.path.exists(checkpoint_path):
    !cd /workspace/bionemo &amp;&amp; \
    python download_artifacts.py --model_dir models --models {model_version}
else:
    print(f&quot;Model {model_version} already exists at {model_path}.&quot;)
</pre></div>
</div>
</div>
</div>
<p>Setting up paths to the data used for model training:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">config_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">bionemo_home</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;examples/protein/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">/conf&#39;</span><span class="p">)</span>
<span class="n">train_fasta</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">SAbDab_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">task_name</span><span class="si">}</span><span class="s1">/train/x000.fasta&#39;</span><span class="p">)</span>
<span class="n">val_fasta</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">SAbDab_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">task_name</span><span class="si">}</span><span class="s1">/val/x000.fasta&#39;</span><span class="p">)</span>
<span class="n">test_fasta</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">SAbDab_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">task_name</span><span class="si">}</span><span class="s1">/test/x000.fasta&#39;</span><span class="p">)</span>
<span class="n">paratope_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">SAbDab_dir</span><span class="p">,</span> <span class="s1">&#39;paratope_custom_dataset&#39;</span><span class="p">)</span>
<span class="o">!</span><span class="w"> </span>mkdir<span class="w"> </span><span class="o">{</span>paratope_dir<span class="o">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mkdir: cannot create directory â€˜/workspace/bionemo/data/processed/SAbDab_Liberis/paratope_custom_datasetâ€™: File exists
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="preprocessing-and-pretraining-from-scratch">
<h2>Preprocessing and Pretraining from Scratch<a class="headerlink" href="#preprocessing-and-pretraining-from-scratch" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Performing preprocessing on the data to transform it into a format that can be used by the model.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%%capture --no-display --no-stderr cell_output
! cd {bionemo_home} &amp;&amp; python examples/protein/esm2nv/pretrain.py \
  --config-path={config_dir} \
  --config-name=pretrain_esm2_650M \
  ++do_training=False \
  ++do_preprocessing=True \
  ++trainer.devices=1 \
  ++model.data.train.custom_pretraining_fasta_path={train_fasta} \
  ++model.data.val.custom_pretraining_fasta_path={val_fasta} \
  ++model.data.test.custom_pretraining_fasta_path={test_fasta} \
  ++model.data.dataset_path={paratope_dir} \
  ++model.data.train.dataset_path={paratope_dir} \
  ++exp_manager.create_wandb_logger=false
</pre></div>
</div>
</div>
</div>
<div class="section" id="pretrain-from-scratch">
<h3>Pretrain from scratch<a class="headerlink" href="#pretrain-from-scratch" title="Permalink to this headline">#</a></h3>
<p>This will take approximately 15 minutes on a A1000 GPU</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%%capture --no-display --no-stderr cell_output
! cd {bionemo_home} &amp;&amp; python examples/protein/esm2nv/pretrain.py \
    --config-path={config_dir} \
    --config-name=pretrain_esm2_650M \
    name={model_name}_from_scratch_antibodies \
    ++do_training=True \
    ++trainer.devices=1 \
    ++trainer.max_steps=1 \
    ++trainer.val_check_interval=1 \
    ++model.data.train.custom_pretraining_fasta_path={train_fasta} \
    ++model.data.val.custom_pretraining_fasta_path={val_fasta} \
    ++model.data.test.custom_pretraining_fasta_path={test_fasta} \
    ++model.data.dataset_path={paratope_dir} \
    ++model.data.train.dataset_path={paratope_dir} \
    ++model.micro_batch_size=1 \
    ++exp_manager.create_wandb_logger=false
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="continue-pretraining-add-a-downstream-head-perform-full-parameter-fine-tuning-for-esm-2nv-on-antibody-sequences">
<h2>Continue Pretraining, Add a Downstream Head, Perform Full Parameter Fine-Tuning for ESM-2nv on Antibody Sequences<a class="headerlink" href="#continue-pretraining-add-a-downstream-head-perform-full-parameter-fine-tuning-for-esm-2nv-on-antibody-sequences" title="Permalink to this headline">#</a></h2>
<div class="section" id="continue-training-from-a-model-checkpoint">
<h3>1. Continue training from a model checkpoint<a class="headerlink" href="#continue-training-from-a-model-checkpoint" title="Permalink to this headline">#</a></h3>
<p>In BioNeMo, you can easily continue training ESM-2nv on antibody sequences from a <code class="docutils literal notranslate"><span class="pre">.nemo</span></code> checkpoint</p>
<div class="alert alert-block alert-info"> <b>IMPORTANT</b>: For demonstration purposes, the `max_steps` and `val_check_interval` parameters in the fine-tuning process have been adjusted to lower values. </div>
<p>To continue the pretraining of the foundation model, use the <code class="docutils literal notranslate"><span class="pre">pretrain.py</span></code> script and set <code class="docutils literal notranslate"><span class="pre">exp_manager.resume_if_exists=True</span></code> to load the model weights, maintain metadata from the previous run (e.g. max_steps) and it picks up from the learning rate at the end of the previous run from the existing <code class="docutils literal notranslate"><span class="pre">esm2nv_650M_converted.nemo</span></code> checkpoint file. You can replace this file with another, but ensure to select the correct config file relative to the model of your choice.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%%capture --no-display --no-stderr cell_output
! cd {bionemo_home} &amp;&amp; python /workspace/bionemo/examples/protein/esm2nv/pretrain.py \
    --config-path={config_dir} \
    --config-name=pretrain_esm2_650M \
    name={model_name}_antibodies_continued \
    do_training=True \
    ++trainer.devices=1 \
    ++trainer.max_steps=1 \
    ++trainer.val_check_interval=1 \
    ++model.data.train.custom_pretraining_fasta_path={train_fasta} \
    ++model.data.val.custom_pretraining_fasta_path={val_fasta} \
    ++model.data.test.custom_pretraining_fasta_path={test_fasta} \
    ++model.data.dataset_path={paratope_dir} \
    ++model.data.train.dataset_path={paratope_dir} \
    ++model.micro_batch_size=1 \
    ++exp_manager.create_wandb_logger=false \
    ++exp_manager.resume_if_exists=true
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="downstream-head-fine-tuning">
<h3>2. Downstream Head Fine-Tuning<a class="headerlink" href="#downstream-head-fine-tuning" title="Permalink to this headline">#</a></h3>
<p>First, note that we are not using the <code class="docutils literal notranslate"><span class="pre">pretrain.py</span></code> script but rather the <code class="docutils literal notranslate"><span class="pre">downstream_flip.py</span></code> script. This script was originally created for downstream fine-tuning on the FLIP dataset. In addition to this Python script, we will use a <code class="docutils literal notranslate"><span class="pre">yaml</span></code> file that already exists in BioNeMo for the <code class="docutils literal notranslate"><span class="pre">token-level-classification</span></code> task, specifically named <code class="docutils literal notranslate"><span class="pre">downstream_flip_sec_str</span></code>. We will override the configurations using Hydra. In particular, we do not want to perform training; instead, we want to add a prediction head, which in this case will be a <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> head for <code class="docutils literal notranslate"><span class="pre">token-level-classification</span></code>.</p>
<p>We will need to adjust the <code class="docutils literal notranslate"><span class="pre">dwnstr_task_validation</span></code> configurations as well as the data used by the <code class="docutils literal notranslate"><span class="pre">model</span></code>. In addition to setting the correct data paths, it is necessary to specify the number of classes we are predicting under <code class="docutils literal notranslate"><span class="pre">target_sizes</span></code> as a list, as these will be used by the CNN. You can also provide mask columns; otherwise, set them to <code class="docutils literal notranslate"><span class="pre">null</span></code> as a list. The <code class="docutils literal notranslate"><span class="pre">target_column</span></code> should be the column in the dataframe where we have the labels, in this case, sequences labeled with <code class="docutils literal notranslate"><span class="pre">N</span></code> and <code class="docutils literal notranslate"><span class="pre">P</span></code> characters. Along with the labels, we need to specify the sequence column as well.</p>
<p>Importantly, we need to set the encoder path to <code class="docutils literal notranslate"><span class="pre">esm2nv_650M_converted.nemo</span></code>. By default, the <code class="docutils literal notranslate"><span class="pre">encoder_frozen</span></code> parameter is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, meaning that the foundation model weights are fixed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">SAbDab_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">task_name</span><span class="si">}</span><span class="s1">/train/x000.csv&#39;</span><span class="p">)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">SAbDab_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">task_name</span><span class="si">}</span><span class="s1">/val/x000.csv&#39;</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">SAbDab_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">task_name</span><span class="si">}</span><span class="s1">/test/x000.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%%capture --no-display --no-stderr cell_output
! cd {bionemo_home} &amp;&amp; python examples/protein/downstream/downstream_flip.py \
    --config-path={config_dir} \
    --config-name=downstream_flip_sec_str \
    name={model_name}_with_head \
    do_training=True \
    do_testing=True \
    ++data.dataset_path={SAbDab_dir} \
    ++trainer.devices=1 \
    ++trainer.max_steps=1 \
    ++trainer.val_check_interval=1 \
    ++model.data.dataset.train={train_data} \
    ++model.data.dataset.val={val_data} \
    ++model.data.dataset.test={test_data} \
    ++model.data.target_column=[&#39;Encoded&#39;] \
    ++model.data.sequence_column=&quot;Antibody&quot; \
    ++model.data.target_sizes=[2] \
    ++model.data.mask_column=[null] \
    ++model.micro_batch_size=1 \
    ++model.data.task_name={task_name} \
    ++model.restore_encoder_path={checkpoint_path} \
    ++model.dwnstr_task_validation.dataset.dataset_path={SAbDab_dir} \
    ++model.data.preprocessed_data_path={SAbDab_dir} \
    ++exp_manager.create_wandb_logger=false
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="full-parameter-fine-tuning">
<h3>3. Full Parameter Fine-Tuning<a class="headerlink" href="#full-parameter-fine-tuning" title="Permalink to this headline">#</a></h3>
<p>Fine-tuning the foundation model will require us to use the <code class="docutils literal notranslate"><span class="pre">downstream_flip.py</span></code> script and set <code class="docutils literal notranslate"><span class="pre">restore_encoder_path</span></code> to load the model weights from the existing checkpoint file. Also, ensure that the encoder weights are not frozen by setting <code class="docutils literal notranslate"><span class="pre">model.encoder_frozen=False</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%%capture --no-display --no-stderr cell_output
! cd {bionemo_home} &amp;&amp; python examples/protein/downstream/downstream_flip.py \
    --config-path={config_dir} \
    --config-name=downstream_flip_sec_str \
    name={model_name}_full_fine_tuning \
    do_training=True \
    do_testing=True \
    ++data.dataset_path={SAbDab_dir} \
    ++trainer.devices=1 \
    ++trainer.max_steps=1 \
    ++trainer.val_check_interval=1 \
    ++model.data.dataset.train={train_data} \
    ++model.data.dataset.val={val_data} \
    ++model.data.dataset.test={test_data} \
    ++model.data.target_column=[&#39;Encoded&#39;] \
    ++model.data.sequence_column=&quot;Antibody&quot; \
    ++model.data.target_sizes=[2] \
    ++model.data.mask_column=[null] \
    ++model.micro_batch_size=1 \
    ++model.data.task_name={task_name} \
    ++model.restore_encoder_path={checkpoint_path} \
    ++model.dwnstr_task_validation.dataset.dataset_path={SAbDab_dir} \
    ++model.data.preprocessed_data_path={SAbDab_dir} \
    ++exp_manager.create_wandb_logger=false \
    ++model.encoder_frozen=False \
    ++exp_manager.resume_if_exists=false
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="low-rank-adaptation-lora-fine-tuning">
<h3>4. Low-Rank Adaptation (LoRA) fine-tuning<a class="headerlink" href="#low-rank-adaptation-lora-fine-tuning" title="Permalink to this headline">#</a></h3>
<p>A few notable changes in the <code class="docutils literal notranslate"><span class="pre">downstream_sec_str_LORA.yaml</span></code> file are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model.encoder_frozen</span></code>= <code class="docutils literal notranslate"><span class="pre">False</span></code>. Set to <code class="docutils literal notranslate"><span class="pre">False</span></code> when using PEFT.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model.peft.enabled</span></code>= <code class="docutils literal notranslate"><span class="pre">True</span></code>. Set to <code class="docutils literal notranslate"><span class="pre">True</span></code> to enable PEFT.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model.peft.lora_tuning.adapter_dim</span></code>: Allows setting different values for the rank used in matrix decomposition. This hyperparameter helps maximize performance on your data, as it determines the number of trainable parameters.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model.peft.lora_tuning.layer_selection</span></code>: Selects the layers in which to add LoRA adapters. For example, <code class="docutils literal notranslate"><span class="pre">[1,12]</span></code> will add LoRA to layer 1 (lowest) and layer 12. <code class="docutils literal notranslate"><span class="pre">null</span></code> will apply adapters to all layers.</p></li>
</ul>
<div class="alert alert-block alert-info"> <b>NOTE</b> LoRA is currently not supported for esm-1nv</div>
<p>Following <span class="xref myst">these instructions</span> and reimplementing the <code class="docutils literal notranslate"><span class="pre">ESM2nvLoRAModel</span></code> class in the <code class="docutils literal notranslate"><span class="pre">bionemo/model/protein/esm1nv/esm1nv_model.py</span></code> script for ESM-1, you can perform LoRA.</p>
<p>For more details about LoRA please see <a class="reference internal" href="esm2_FLIP_finetuning.html"><span class="doc std std-doc">this</span></a> notebook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%%capture --no-display --no-stderr cell_output
! cd {bionemo_home} &amp;&amp; python examples/protein/downstream/downstream_flip.py \
    --config-path={config_dir} \
    --config-name=downstream_sec_str_LORA \
    name={model_name}_LORA \
    do_training=True \
    do_testing=True \
    ++data.dataset_path={SAbDab_dir} \
    ++trainer.devices=1 \
    ++trainer.max_steps=1 \
    ++trainer.max_epochs=1 \
    ++trainer.val_check_interval=1 \
    ++model.encoder_frozen=False \
    ++model.data.task_name={task_name} \
    ++model.restore_encoder_path={checkpoint_path} \
    ++model.data.preprocessed_data_path={SAbDab_dir} \
    ++model.data.dataset.train={train_data} \
    ++model.data.dataset.val={val_data} \
    ++model.data.dataset.test={test_data} \
    ++model.data.target_column=[&#39;Encoded&#39;] \
    ++model.data.sequence_column=&quot;Antibody&quot; \
    ++model.data.target_sizes=[2] \
    ++model.data.mask_column=[null] \
    ++model.dwnstr_task_validation.dataset.target_column=[&#39;Encoded&#39;] \
    ++model.dwnstr_task_validation.dataset.sequence_column=&quot;Antibody&quot; \
    ++model.dwnstr_task_validation.dataset.target_sizes=[2] \
    ++model.dwnstr_task_validation.data_impl_kwargs.csv_mmap.data_col=1 \
    ++model.dwnstr_task_validation.dataset.mask_column=[null] \
    ++model.dwnstr_task_validation.dataset.dataset_path={SAbDab_dir} \
    ++exp_manager.create_wandb_logger=false \
    ++exp_manager.resume_if_exists=false
</pre></div>
</div>
</div>
</div>
<p>In this demo, we explored how to continue training ESM-2nv, add a downstream head, and perform full-parameter fine-tuning (both the foundation model and the head) for a token-level classification task on antibody sequences.</p>
</div>
</div>
</div>

<div class="section">
   
</div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="esm2_oas_inferencing.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Performing inference on OAS sequences with ESM-2nv</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="dnabert_inference.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Generating and visualizing embeddings with DNABert</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By NVIDIA<br/>
  
      &copy; Copyright 2023-2024 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved..<br/>
    Last updated on Nov 20, 2024.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>