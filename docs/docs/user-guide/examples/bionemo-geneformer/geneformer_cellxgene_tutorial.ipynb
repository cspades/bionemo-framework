{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a88d40b-64de-4661-b3b0-7a4b87ba0162",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BioNeMo - Geneformer inferencing for single cell downstream tasks\n",
    "\n",
    "This tutorial showcases how to run the BioNeMo container, pre-train a geneformer model, and use it for inferencing downstream single cell tasks. At the end of this tutorial, a user will learn:\n",
    "- launching the BioNeMo container\n",
    "- Download data from czi to use for pre-training and inference.\n",
    "- Convert AnnData files into the sparse SCDL memmap format used by BioNeMo\n",
    "- Kick-off pretraining with a custom single cell dataset\n",
    "- Restore the pre-trained model and perform inference with the same czi dataset.\n",
    "\n",
    "\n",
    "### Prerequisites:\n",
    "- BioNeMo Framework container is running (refer to the [Getting Started](../index.md) section)\n",
    "\n",
    "\n",
    "#### Running the BioNeMo container\n",
    "\n",
    "This example has been built by launching the container in a local machine with 2 x A6000 RTX GPUs. Refer to specific instructions for [remote and multi-node launch]\n",
    "\n",
    "Once the container is launched, navigate to http://0.0.0.0:8888, http://localhost:8888, or the IP address of the workstation/node. A JupyterLab instance should show up.\n",
    "\n",
    "#### Copy this code and input files into JupyterLab\n",
    "\n",
    "In the launched JupyterLab, run the codes in a Jupyter notebook as provided in the code cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e47327a-6549-4ff4-a32a-a32d07a1e706",
   "metadata": {},
   "source": [
    "## Getting example single cell data and setting it up for inference\n",
    "\n",
    "First, we must acquire single cell training data for inference. To do this we will install the cellxgene-census api and download a small dataset. We use the example provided by the czi api examples page to download a single h5ad file. Generally, our workflow expects a collection of h5ad files to be used for pre-training. In this case, we restrict to 100k cells from a single dataset  to keep training time and downloading time small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056ca29a-ffa1-4381-83b6-cad9a7b0c4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: cellxgene-census in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
      "Requirement already satisfied: tiledbsoma!=1.14.1,>=1.12.3 in /usr/local/lib/python3.12/dist-packages (from cellxgene-census) (1.16.0)\n",
      "Requirement already satisfied: anndata in /usr/local/lib/python3.12/dist-packages (from cellxgene-census) (0.11.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.23 in /usr/local/lib/python3.12/dist-packages (from cellxgene-census) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from cellxgene-census) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from cellxgene-census) (4.12.2)\n",
      "Requirement already satisfied: s3fs>=2021.06.1 in /usr/local/lib/python3.12/dist-packages (from cellxgene-census) (2024.10.0)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /usr/local/lib/python3.12/dist-packages (from s3fs>=2021.06.1->cellxgene-census) (2.13.3)\n",
      "Requirement already satisfied: fsspec==2024.10.0.* in /usr/local/lib/python3.12/dist-packages (from s3fs>=2021.06.1->cellxgene-census) (2024.10.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from s3fs>=2021.06.1->cellxgene-census) (3.11.10)\n",
      "Requirement already satisfied: attrs>=22.2 in /usr/local/lib/python3.12/dist-packages (from tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (24.2.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (2.2.2)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (17.0.0)\n",
      "Requirement already satisfied: scanpy>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (1.10.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (1.14.1)\n",
      "Requirement already satisfied: somacore==1.0.28 in /usr/local/lib/python3.12/dist-packages (from tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (1.0.28)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.12/dist-packages (from somacore==1.0.28->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (0.6)\n",
      "Requirement already satisfied: shapely in /usr/local/lib/python3.12/dist-packages (from somacore==1.0.28->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (2.0.7)\n",
      "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /usr/local/lib/python3.12/dist-packages (from anndata->cellxgene-census) (1.11.1)\n",
      "Requirement already satisfied: h5py>=3.7 in /usr/local/lib/python3.12/dist-packages (from anndata->cellxgene-census) (3.13.0)\n",
      "Requirement already satisfied: natsort in /usr/local/lib/python3.12/dist-packages (from anndata->cellxgene-census) (8.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from anndata->cellxgene-census) (24.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->cellxgene-census) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->cellxgene-census) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->cellxgene-census) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->cellxgene-census) (2024.12.14)\n",
      "Requirement already satisfied: botocore<1.34.163,>=1.34.70 in /usr/local/lib/python3.12/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2021.06.1->cellxgene-census) (1.34.151)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.12/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2021.06.1->cellxgene-census) (1.17.2)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2021.06.1->cellxgene-census) (0.12.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2021.06.1->cellxgene-census) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2021.06.1->cellxgene-census) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2021.06.1->cellxgene-census) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2021.06.1->cellxgene-census) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2021.06.1->cellxgene-census) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2021.06.1->cellxgene-census) (1.18.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (2024.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (1.4.2)\n",
      "Requirement already satisfied: legacy-api-wrap>=1.4 in /usr/local/lib/python3.12/dist-packages (from scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.12/dist-packages (from scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (3.10.0)\n",
      "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.12/dist-packages (from scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (3.4.2)\n",
      "Requirement already satisfied: numba>=0.56 in /usr/local/lib/python3.12/dist-packages (from scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (0.61.0)\n",
      "Requirement already satisfied: patsy!=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (1.0.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.12/dist-packages (from scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (0.5.13)\n",
      "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.12/dist-packages (from scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (1.6.1)\n",
      "Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.12/dist-packages (from scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (0.13.2)\n",
      "Requirement already satisfied: session-info in /usr/local/lib/python3.12/dist-packages (from scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (1.0.0)\n",
      "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.12/dist-packages (from scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (0.14.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (4.67.1)\n",
      "Requirement already satisfied: umap-learn!=0.5.0,>=0.5 in /usr/local/lib/python3.12/dist-packages (from scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (0.5.7)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.34.163,>=1.34.70->aiobotocore<3.0.0,>=2.5.4->s3fs>=2021.06.1->cellxgene-census) (1.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (3.2.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.56->scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (0.44.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1->scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (3.5.0)\n",
      "Requirement already satisfied: stdlib-list in /usr/local/lib/python3.12/dist-packages (from session-info->scanpy>=1.9.2->tiledbsoma!=1.14.1,>=1.12.3->cellxgene-census) (0.11.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install cellxgene-census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f579ac-0207-4e07-8f34-dac0cd955c53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Below are paths required for setting up pre-training and inference.\n",
    "tutorial_data_dir = \"/workspace/bionemo2/data/singlecell_tutorial/download_anndata\"\n",
    "train_tutorial_data_dir = \"/workspace/bionemo2/data/singlecell_tutorial/download_anndata/train\"\n",
    "val_tutorial_data_dir = \"/workspace/bionemo2/data/singlecell_tutorial/download_anndata/val\"\n",
    "test_tutorial_data_dir = \"/workspace/bionemo2/data/singlecell_tutorial/download_anndata/test\"\n",
    "\n",
    "train_tutorial_processed_dir = \"/workspace/bionemo2/data/singlecell_tutorial/processed_data/train\"\n",
    "val_tutorial_processed_dir = \"/workspace/bionemo2/data/singlecell_tutorial/processed_data/val\"\n",
    "test_tutorial_processed_dir = \"/workspace/bionemo2/data/singlecell_tutorial/processed_data/test\"\n",
    "tutorial_output_dir = \"/workspace/bionemo2/data/singlecell_tutorial/inference_output\"\n",
    "tutorial_output_inference_pickle = f\"{tutorial_output_dir}/human_covid19_bcells_from_scratch.pkl\"\n",
    "demo_data_train_download_path = f\"{train_tutorial_data_dir}/human_covid19_bcells.h5ad\"\n",
    "demo_data_val_download_path = f\"{val_tutorial_data_dir}/human_covid19_bcells.h5ad\"\n",
    "demo_data_test_download_path = f\"{test_tutorial_data_dir}/human_covid19_bcells.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88bd2844-0251-476e-9e3f-8d4e89474f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p {train_tutorial_data_dir}\n",
    "!mkdir -p {val_tutorial_data_dir}\n",
    "!mkdir -p {test_tutorial_data_dir}\n",
    "!mkdir -p {train_tutorial_processed_dir}\n",
    "!mkdir -p {val_tutorial_processed_dir}\n",
    "!mkdir -p {test_tutorial_processed_dir}\n",
    "!mkdir -p {tutorial_output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ccf03f0-1590-434e-a314-8ff0a02f5ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from optuna import progress_bar as pbar_module\n"
     ]
    }
   ],
   "source": [
    "import cellxgene_census\n",
    "frac_train = 0.8\n",
    "frac_val = 0.1\n",
    "frac_test = 0.1\n",
    "\n",
    "with cellxgene_census.open_soma(census_version=\"2023-12-15\") as census:\n",
    "    filter1 = \"cell_type == 'B cell' and tissue_general == 'lung' and disease == 'COVID-19' and is_primary_data == True\"\n",
    "\n",
    "    adata = cellxgene_census.get_anndata(\n",
    "        census = census,\n",
    "        organism = \"Homo sapiens\",\n",
    "        obs_value_filter = filter1,\n",
    "    )\n",
    "    n_train = int(adata.shape[0] * frac_train)\n",
    "    n_val = int(adata.shape[0] * frac_val)\n",
    "    n_test = adata.shape[0] - n_train - n_val\n",
    "    # Create some splits, bad practice since ordering may be a thing but let's just take ranges for this demo.\n",
    "    adata_train = adata[0:n_train].copy()\n",
    "    adata_val = adata[n_train:(n_train+n_val)].copy()\n",
    "    adata_test = adata[(n_train+n_val):].copy()\n",
    "    adata_train.write(demo_data_train_download_path)\n",
    "    adata_val.write(demo_data_val_download_path)\n",
    "    adata_test.write(demo_data_test_download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b060e73b-a3f9-4315-ae91-c23b9a29f490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "!rm -rf  {train_tutorial_processed_dir}\n",
    "!rm -rf  {val_tutorial_processed_dir}\n",
    "!rm -rf  {test_tutorial_processed_dir}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b076e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data processed directory\n",
    "!convert_h5ad_to_scdl \\\n",
    "  --data-path {train_tutorial_data_dir} \\\n",
    "  --save-path {train_tutorial_processed_dir}\n",
    "\n",
    "# Create validation data processed directory\n",
    "!convert_h5ad_to_scdl \\\n",
    "  --data-path {val_tutorial_data_dir} \\\n",
    "  --save-path {val_tutorial_processed_dir}\n",
    "\n",
    "# Create test data processed directory\n",
    "!convert_h5ad_to_scdl \\\n",
    "  --data-path {test_tutorial_data_dir} \\\n",
    "  --save-path {test_tutorial_processed_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd212acb-9695-4ec4-bff6-8669693118f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8.0K\n",
      "drwxr-xr-x 5 jomitchell domain-users 4.0K Mar 11 18:57 ..\n",
      "drwxr-xr-x 2 jomitchell domain-users 4.0K Mar 11 18:57 .\n"
     ]
    }
   ],
   "source": [
    "!ls -laht {train_tutorial_processed_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43efdd-8ba5-4a3b-8f70-9b5839ec075c",
   "metadata": {},
   "source": [
    "# Pretraining\n",
    "Now that we have converted the h5ad files to scdl memmapped files we can begin training. We will kickoff training.\n",
    "\n",
    "Check the full recipe/config file in `pretrain-recipe-short.yaml` for a complete list of arguments and config parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ffaf4085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/workspace/bionemo2/data/singlecell_tutorial/processed_data/train'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See where the processed data is stored\n",
    "{train_tutorial_processed_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7ac56b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-11 20:30:23 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[NeMo I 2025-03-11 20:30:26 nemo_logging:393] Saved configuration to args.dest='pretrain-recipe-short.yaml'\n"
     ]
    }
   ],
   "source": [
    "# Create the recipe file\n",
    "!bionemo-geneformer-recipe --recipe geneformer_10m_shortpretrain_recipe --dest pretrain-recipe-short.yaml --result-dir /workspace/bionemo2/results --data-path /workspace/bionemo2/data/singlecell_tutorial/processed_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8cfe4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-11 20:30:42 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[NeMo W 2025-03-11 20:30:45 nemo_logging:405] Tokenizer vocab file: /workspace/bionemo2/data/singlecell_tutorial/processed_data/train/geneformer.vocab already exists. Overwriting...\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] Resource already exists, skipping download: https://huggingface.co/ctheodoris/Geneformer/resolve/main/geneformer/gene_dictionaries_30m/gene_name_id_dict_gc30M.pkl?download=true\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] Resource already exists, skipping download: https://huggingface.co/ctheodoris/Geneformer/resolve/main/geneformer/gene_dictionaries_30m/gene_median_dictionary_gc30M.pkl?download=true\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] *************** Preprocessing Finished ************\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-03-11 20:30:45 nemo_logging:405] User-set tensorboard is currently turned off. Internally one may still be set by NeMo2.\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] Experiments will be logged at /workspace/bionemo2/results/geneformer-10m/dev\n",
      "[NeMo W 2025-03-11 20:30:45 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /workspace/bionemo2/results\n",
      "[NeMo W 2025-03-11 20:30:45 nemo_logging:405] \"update_logger_directory\" is True. Overwriting wandb logger \"save_dir\" to /workspace/bionemo2/results/geneformer-10m\n",
      "[NeMo W 2025-03-11 20:30:45 nemo_logging:405] The Trainer already contains a ModelCheckpoint callback. This will be overwritten.\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-03-11 20:30:45 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 1.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /workspace/bionemo2/results/geneformer-10m/dev/checkpoints exists and is not empty.\n",
      "\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/models/bert/bert_layer_specs.py:79: UserWarning: Attribute bert_layer_specs.bert_layer_with_transformer_engine_spec is on a\n",
      "            deprecation track and will be removed in future releases. Please migrate to\n",
      "            bert_layer_specs.get_bert_layer_with_transformer_engine_spec().\n",
      "  warnings.warn(\n",
      "\n",
      "[NeMo I 2025-03-11 20:30:47 nemo_logging:393] Padded vocab_size: 25472, original vocab_size: 25429, dummy tokens: 43.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "[NeMo I 2025-03-11 20:30:47 nemo_logging:393] Copying Trainer's 'max_steps' (500) to LR scheduler's 'max_steps'.\n",
      "[NeMo I 2025-03-11 20:30:47 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-03-11 20:30:47 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 10300032\n",
      "[NeMo I 2025-03-11 20:30:47 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=True, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=40000000, average_in_collective=True, fp8_param_gather=False)\n",
      "[NeMo I 2025-03-11 20:30:47 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (10300032 elements):\n",
      "    \tmodule.output_layer.bias\n",
      "    \tmodule.encoder.layers.3.mlp.linear_fc1.layer_norm_bias\n",
      "    \tmodule.encoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.encoder.layers.4.self_attention.linear_qkv.weight\n",
      "    \tmodule.encoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.encoder.layers.1.self_attention.linear_proj.bias\n",
      "    \tmodule.encoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.encoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.encoder.layers.0.self_attention.linear_qkv.bias\n",
      "    \tmodule.encoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.encoder.layers.1.self_attention.linear_qkv.bias\n",
      "    \tmodule.encoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.encoder.layers.2.mlp.linear_fc1.layer_norm_bias\n",
      "    \tmodule.encoder.layers.0.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.encoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.encoder.layers.0.mlp.linear_fc2.bias\n",
      "    \tmodule.encoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.encoder.layers.2.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.encoder.layers.2.self_attention.linear_proj.bias\n",
      "    \tmodule.encoder.final_layernorm.weight\n",
      "    \tmodule.encoder.layers.5.mlp.linear_fc2.bias\n",
      "    \tmodule.encoder.layers.5.mlp.linear_fc1.bias\n",
      "    \tmodule.encoder.layers.0.mlp.linear_fc1.layer_norm_bias\n",
      "    \tmodule.encoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.encoder.layers.1.mlp.linear_fc1.layer_norm_bias\n",
      "    \tmodule.encoder.layers.2.self_attention.linear_qkv.weight\n",
      "    \tmodule.encoder.layers.0.self_attention.linear_proj.weight\n",
      "    \tmodule.encoder.layers.4.self_attention.linear_proj.bias\n",
      "    \tmodule.encoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.encoder.layers.4.mlp.linear_fc2.bias\n",
      "    \tmodule.encoder.layers.4.mlp.linear_fc1.bias\n",
      "    \tmodule.encoder.layers.0.self_attention.linear_proj.bias\n",
      "    \tmodule.lm_head.dense.weight\n",
      "    \tmodule.encoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.encoder.layers.0.self_attention.linear_qkv.weight\n",
      "    \tmodule.encoder.layers.5.self_attention.linear_proj.weight\n",
      "    \tmodule.encoder.layers.1.self_attention.linear_qkv.weight\n",
      "    \tmodule.encoder.layers.5.self_attention.linear_qkv.layer_norm_bias\n",
      "    \tmodule.encoder.layers.2.mlp.linear_fc2.bias\n",
      "    \tmodule.encoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.encoder.layers.3.mlp.linear_fc2.bias\n",
      "    \tmodule.encoder.layers.3.mlp.linear_fc1.bias\n",
      "    \tmodule.encoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.lm_head.dense.bias\n",
      "    \tmodule.encoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.encoder.layers.4.self_attention.linear_proj.weight\n",
      "    \tmodule.encoder.layers.1.self_attention.linear_proj.weight\n",
      "    \tmodule.encoder.layers.4.self_attention.linear_qkv.layer_norm_bias\n",
      "    \tmodule.encoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.encoder.layers.5.self_attention.linear_qkv.bias\n",
      "    \tmodule.encoder.layers.2.mlp.linear_fc1.bias\n",
      "    \tmodule.encoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.encoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.encoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.encoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.encoder.layers.1.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.encoder.layers.0.mlp.linear_fc1.bias\n",
      "    \tmodule.lm_head.layer_norm.weight\n",
      "    \tmodule.encoder.layers.3.self_attention.linear_qkv.layer_norm_bias\n",
      "    \tmodule.encoder.layers.4.self_attention.linear_qkv.bias\n",
      "    \tmodule.encoder.layers.1.mlp.linear_fc1.bias\n",
      "    \tmodule.embedding.position_embeddings.weight\n",
      "    \tmodule.encoder.layers.5.mlp.linear_fc1.layer_norm_bias\n",
      "    \tmodule.encoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.encoder.layers.2.self_attention.linear_proj.weight\n",
      "    \tmodule.encoder.layers.5.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.encoder.layers.2.self_attention.linear_qkv.layer_norm_bias\n",
      "    \tmodule.encoder.layers.1.mlp.linear_fc2.bias\n",
      "    \tmodule.lm_head.layer_norm.bias\n",
      "    \tmodule.encoder.layers.3.self_attention.linear_qkv.bias\n",
      "    \tmodule.encoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.encoder.layers.5.self_attention.linear_proj.bias\n",
      "    \tmodule.encoder.layers.4.mlp.linear_fc1.layer_norm_bias\n",
      "    \tmodule.encoder.final_layernorm.bias\n",
      "    \tmodule.encoder.layers.5.self_attention.linear_qkv.weight\n",
      "    \tmodule.encoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.encoder.layers.0.self_attention.linear_qkv.layer_norm_bias\n",
      "    \tmodule.encoder.layers.4.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.encoder.layers.1.self_attention.linear_qkv.layer_norm_bias\n",
      "    \tmodule.encoder.layers.2.self_attention.linear_qkv.bias\n",
      "[NeMo I 2025-03-11 20:30:47 utils:302] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.001, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=True, params_dtype=torch.bfloat16, use_precision_aware_optimizer=False, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=False, optimizer_offload_fraction=0.0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=False, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')\n",
      "┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName                             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType               \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ module                            │ DDP                 │ 10.3 M │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ module.module                     │ Float16Module       │ 10.3 M │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ module.module.module              │ MegatronBioBertMod… │ 10.3 M │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ module.module.module.embedding    │ LanguageModelEmbed… │  7.0 M │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ module.module.module.encoder      │ TransformerBlock    │  3.2 M │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ module.module.module.lm_head      │ BertLMHead          │ 66.3 K │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0m│ module.module.module.output_layer │ ColumnParallelLine… │ 25.5 K │ train │\n",
      "└───┴───────────────────────────────────┴─────────────────────┴────────┴───────┘\n",
      "\u001b[1mTrainable params\u001b[0m: 10.3 M                                                        \n",
      "\u001b[1mNon-trainable params\u001b[0m: 0                                                         \n",
      "\u001b[1mTotal params\u001b[0m: 10.3 M                                                            \n",
      "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 41                                      \n",
      "\u001b[1mModules in train mode\u001b[0m: 134                                                      \n",
      "\u001b[1mModules in eval mode\u001b[0m: 0                                                         \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n",
      "\n",
      "Sanity checking Validation: iteration 1/2\n",
      "Sanity checking Validation: iteration 2/2\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('global_batch_size', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n",
      "\n",
      "[NeMo W 2025-03-11 20:30:50 rerun_state_machine:1264] Implicit initialization of Rerun State Machine!\n",
      "[NeMo W 2025-03-11 20:30:50 rerun_state_machine:239] RerunStateMachine initialized in mode RerunMode.DISABLED\n",
      "Training epoch 0, iteration 0/499 | lr: 0 | global_batch_size: 8 | global_step: 0 | reduced_train_loss: 10.2\n",
      "Training epoch 0, iteration 1/499 | lr: 0.0002 | global_batch_size: 8 | global_step: 1 | reduced_train_loss: 10.22 | consumed_samples: 16\n",
      "Training epoch 0, iteration 2/499 | lr: 0.0004 | global_batch_size: 8 | global_step: 2 | reduced_train_loss: 10.16 | consumed_samples: 24\n",
      "Training epoch 0, iteration 3/499 | lr: 0.0006 | global_batch_size: 8 | global_step: 3 | reduced_train_loss: 10.15 | consumed_samples: 32\n",
      "Training epoch 0, iteration 4/499 | lr: 0.0008 | global_batch_size: 8 | global_step: 4 | reduced_train_loss: 10.1 | consumed_samples: 40\n",
      "Training epoch 0, iteration 5/499 | lr: 0.001 | global_batch_size: 8 | global_step: 5 | reduced_train_loss: 10.03 | consumed_samples: 48\n",
      "Training epoch 0, iteration 6/499 | lr: 0.001 | global_batch_size: 8 | global_step: 6 | reduced_train_loss: 9.936 | consumed_samples: 56\n",
      "Training epoch 0, iteration 7/499 | lr: 0.001 | global_batch_size: 8 | global_step: 7 | reduced_train_loss: 9.892 | consumed_samples: 64\n",
      "Training epoch 0, iteration 8/499 | lr: 0.0009999 | global_batch_size: 8 | global_step: 8 | reduced_train_loss: 9.755 | consumed_samples: 72\n",
      "Training epoch 0, iteration 9/499 | lr: 0.0009998 | global_batch_size: 8 | global_step: 9 | reduced_train_loss: 9.874 | consumed_samples: 80\n",
      "Training epoch 0, iteration 10/499 | lr: 0.0009997 | global_batch_size: 8 | global_step: 10 | reduced_train_loss: 9.638 | consumed_samples: 88\n",
      "Training epoch 0, iteration 11/499 | lr: 0.0009996 | global_batch_size: 8 | global_step: 11 | reduced_train_loss: 9.563 | consumed_samples: 96\n",
      "Training epoch 0, iteration 12/499 | lr: 0.0009995 | global_batch_size: 8 | global_step: 12 | reduced_train_loss: 9.439 | consumed_samples: 104\n",
      "Training epoch 0, iteration 13/499 | lr: 0.0009993 | global_batch_size: 8 | global_step: 13 | reduced_train_loss: 9.354 | consumed_samples: 112\n",
      "Training epoch 0, iteration 14/499 | lr: 0.0009991 | global_batch_size: 8 | global_step: 14 | reduced_train_loss: 9.363 | consumed_samples: 120\n",
      "Training epoch 0, iteration 15/499 | lr: 0.0009989 | global_batch_size: 8 | global_step: 15 | reduced_train_loss: 9.414 | consumed_samples: 128\n",
      "Training epoch 0, iteration 16/499 | lr: 0.0009987 | global_batch_size: 8 | global_step: 16 | reduced_train_loss: 9.712 | consumed_samples: 136\n",
      "Training epoch 0, iteration 17/499 | lr: 0.0009984 | global_batch_size: 8 | global_step: 17 | reduced_train_loss: 9.278 | consumed_samples: 144\n",
      "Training epoch 0, iteration 18/499 | lr: 0.0009981 | global_batch_size: 8 | global_step: 18 | reduced_train_loss: 9.324 | consumed_samples: 152\n",
      "Training epoch 0, iteration 19/499 | lr: 0.0009978 | global_batch_size: 8 | global_step: 19 | reduced_train_loss: 9.349 | consumed_samples: 160\n",
      "Training epoch 0, iteration 20/499 | lr: 0.0009975 | global_batch_size: 8 | global_step: 20 | reduced_train_loss: 9.126 | consumed_samples: 168\n",
      "Training epoch 0, iteration 21/499 | lr: 0.0009972 | global_batch_size: 8 | global_step: 21 | reduced_train_loss: 9.195 | consumed_samples: 176\n",
      "Training epoch 0, iteration 22/499 | lr: 0.0009968 | global_batch_size: 8 | global_step: 22 | reduced_train_loss: 9.149 | consumed_samples: 184\n",
      "Training epoch 0, iteration 23/499 | lr: 0.0009964 | global_batch_size: 8 | global_step: 23 | reduced_train_loss: 9.092 | consumed_samples: 192\n",
      "Training epoch 0, iteration 24/499 | lr: 0.000996 | global_batch_size: 8 | global_step: 24 | reduced_train_loss: 9.053 | consumed_samples: 200\n",
      "Training epoch 0, iteration 25/499 | lr: 0.0009956 | global_batch_size: 8 | global_step: 25 | reduced_train_loss: 9.113 | consumed_samples: 208\n",
      "Training epoch 0, iteration 26/499 | lr: 0.0009951 | global_batch_size: 8 | global_step: 26 | reduced_train_loss: 9.053 | consumed_samples: 216\n",
      "Training epoch 0, iteration 27/499 | lr: 0.0009947 | global_batch_size: 8 | global_step: 27 | reduced_train_loss: 9.014 | consumed_samples: 224\n",
      "Training epoch 0, iteration 28/499 | lr: 0.0009942 | global_batch_size: 8 | global_step: 28 | reduced_train_loss: 9.143 | consumed_samples: 232\n",
      "Training epoch 0, iteration 29/499 | lr: 0.0009936 | global_batch_size: 8 | global_step: 29 | reduced_train_loss: 9.279 | consumed_samples: 240\n",
      "Training epoch 0, iteration 30/499 | lr: 0.0009931 | global_batch_size: 8 | global_step: 30 | reduced_train_loss: 9.261 | consumed_samples: 248\n",
      "Training epoch 0, iteration 31/499 | lr: 0.0009925 | global_batch_size: 8 | global_step: 31 | reduced_train_loss: 9.094 | consumed_samples: 256\n",
      "Training epoch 0, iteration 32/499 | lr: 0.000992 | global_batch_size: 8 | global_step: 32 | reduced_train_loss: 9.157 | consumed_samples: 264\n",
      "Training epoch 0, iteration 33/499 | lr: 0.0009914 | global_batch_size: 8 | global_step: 33 | reduced_train_loss: 9.072 | consumed_samples: 272\n",
      "Training epoch 0, iteration 34/499 | lr: 0.0009907 | global_batch_size: 8 | global_step: 34 | reduced_train_loss: 9.077 | consumed_samples: 280\n",
      "Training epoch 0, iteration 35/499 | lr: 0.0009901 | global_batch_size: 8 | global_step: 35 | reduced_train_loss: 9.081 | consumed_samples: 288\n",
      "Training epoch 0, iteration 36/499 | lr: 0.0009894 | global_batch_size: 8 | global_step: 36 | reduced_train_loss: 9.219 | consumed_samples: 296\n",
      "Training epoch 0, iteration 37/499 | lr: 0.0009887 | global_batch_size: 8 | global_step: 37 | reduced_train_loss: 9.05 | consumed_samples: 304\n",
      "Training epoch 0, iteration 38/499 | lr: 0.000988 | global_batch_size: 8 | global_step: 38 | reduced_train_loss: 9.129 | consumed_samples: 312\n",
      "Training epoch 0, iteration 39/499 | lr: 0.0009873 | global_batch_size: 8 | global_step: 39 | reduced_train_loss: 8.964 | consumed_samples: 320\n",
      "Training epoch 0, iteration 40/499 | lr: 0.0009865 | global_batch_size: 8 | global_step: 40 | reduced_train_loss: 9.11 | consumed_samples: 328\n",
      "Training epoch 0, iteration 41/499 | lr: 0.0009857 | global_batch_size: 8 | global_step: 41 | reduced_train_loss: 9.192 | consumed_samples: 336\n",
      "Training epoch 0, iteration 42/499 | lr: 0.0009849 | global_batch_size: 8 | global_step: 42 | reduced_train_loss: 9.07 | consumed_samples: 344\n",
      "Training epoch 0, iteration 43/499 | lr: 0.0009841 | global_batch_size: 8 | global_step: 43 | reduced_train_loss: 9.102 | consumed_samples: 352\n",
      "Training epoch 0, iteration 44/499 | lr: 0.0009833 | global_batch_size: 8 | global_step: 44 | reduced_train_loss: 8.867 | consumed_samples: 360\n",
      "Training epoch 0, iteration 45/499 | lr: 0.0009824 | global_batch_size: 8 | global_step: 45 | reduced_train_loss: 8.885 | consumed_samples: 368\n",
      "Training epoch 0, iteration 46/499 | lr: 0.0009815 | global_batch_size: 8 | global_step: 46 | reduced_train_loss: 9.076 | consumed_samples: 376\n",
      "Training epoch 0, iteration 47/499 | lr: 0.0009806 | global_batch_size: 8 | global_step: 47 | reduced_train_loss: 8.848 | consumed_samples: 384\n",
      "Training epoch 0, iteration 48/499 | lr: 0.0009797 | global_batch_size: 8 | global_step: 48 | reduced_train_loss: 9.141 | consumed_samples: 392\n",
      "Training epoch 0, iteration 49/499 | lr: 0.0009787 | global_batch_size: 8 | global_step: 49 | reduced_train_loss: 9.034 | consumed_samples: 400\n",
      "Training epoch 0, iteration 50/499 | lr: 0.0009778 | global_batch_size: 8 | global_step: 50 | reduced_train_loss: 8.954 | consumed_samples: 408\n",
      "Training epoch 0, iteration 51/499 | lr: 0.0009768 | global_batch_size: 8 | global_step: 51 | reduced_train_loss: 8.871 | consumed_samples: 416\n",
      "Training epoch 0, iteration 52/499 | lr: 0.0009758 | global_batch_size: 8 | global_step: 52 | reduced_train_loss: 9.038 | consumed_samples: 424\n",
      "Training epoch 0, iteration 53/499 | lr: 0.0009747 | global_batch_size: 8 | global_step: 53 | reduced_train_loss: 8.948 | consumed_samples: 432\n",
      "Training epoch 0, iteration 54/499 | lr: 0.0009737 | global_batch_size: 8 | global_step: 54 | reduced_train_loss: 8.997 | consumed_samples: 440\n",
      "Training epoch 0, iteration 55/499 | lr: 0.0009726 | global_batch_size: 8 | global_step: 55 | reduced_train_loss: 9.07 | consumed_samples: 448\n",
      "Training epoch 0, iteration 56/499 | lr: 0.0009715 | global_batch_size: 8 | global_step: 56 | reduced_train_loss: 9.043 | consumed_samples: 456\n",
      "Training epoch 0, iteration 57/499 | lr: 0.0009704 | global_batch_size: 8 | global_step: 57 | reduced_train_loss: 8.786 | consumed_samples: 464\n",
      "Training epoch 0, iteration 58/499 | lr: 0.0009693 | global_batch_size: 8 | global_step: 58 | reduced_train_loss: 9.051 | consumed_samples: 472\n",
      "Training epoch 0, iteration 59/499 | lr: 0.0009681 | global_batch_size: 8 | global_step: 59 | reduced_train_loss: 8.978 | consumed_samples: 480\n",
      "Training epoch 0, iteration 60/499 | lr: 0.0009669 | global_batch_size: 8 | global_step: 60 | reduced_train_loss: 9.03 | consumed_samples: 488\n",
      "Training epoch 0, iteration 61/499 | lr: 0.0009657 | global_batch_size: 8 | global_step: 61 | reduced_train_loss: 9.033 | consumed_samples: 496\n",
      "Training epoch 0, iteration 62/499 | lr: 0.0009645 | global_batch_size: 8 | global_step: 62 | reduced_train_loss: 8.892 | consumed_samples: 504\n",
      "Training epoch 0, iteration 63/499 | lr: 0.0009633 | global_batch_size: 8 | global_step: 63 | reduced_train_loss: 8.979 | consumed_samples: 512\n",
      "Training epoch 0, iteration 64/499 | lr: 0.000962 | global_batch_size: 8 | global_step: 64 | reduced_train_loss: 8.886 | consumed_samples: 520\n",
      "Training epoch 0, iteration 65/499 | lr: 0.0009607 | global_batch_size: 8 | global_step: 65 | reduced_train_loss: 8.889 | consumed_samples: 528\n",
      "Training epoch 0, iteration 66/499 | lr: 0.0009594 | global_batch_size: 8 | global_step: 66 | reduced_train_loss: 8.986 | consumed_samples: 536\n",
      "Training epoch 0, iteration 67/499 | lr: 0.0009581 | global_batch_size: 8 | global_step: 67 | reduced_train_loss: 8.949 | consumed_samples: 544\n",
      "Training epoch 0, iteration 68/499 | lr: 0.0009568 | global_batch_size: 8 | global_step: 68 | reduced_train_loss: 8.966 | consumed_samples: 552\n",
      "Training epoch 0, iteration 69/499 | lr: 0.0009554 | global_batch_size: 8 | global_step: 69 | reduced_train_loss: 8.76 | consumed_samples: 560\n",
      "Training epoch 0, iteration 70/499 | lr: 0.000954 | global_batch_size: 8 | global_step: 70 | reduced_train_loss: 8.899 | consumed_samples: 568\n",
      "Training epoch 0, iteration 71/499 | lr: 0.0009526 | global_batch_size: 8 | global_step: 71 | reduced_train_loss: 8.761 | consumed_samples: 576\n",
      "Training epoch 0, iteration 72/499 | lr: 0.0009512 | global_batch_size: 8 | global_step: 72 | reduced_train_loss: 8.817 | consumed_samples: 584\n",
      "Training epoch 0, iteration 73/499 | lr: 0.0009497 | global_batch_size: 8 | global_step: 73 | reduced_train_loss: 8.963 | consumed_samples: 592\n",
      "Training epoch 0, iteration 74/499 | lr: 0.0009483 | global_batch_size: 8 | global_step: 74 | reduced_train_loss: 8.893 | consumed_samples: 600\n",
      "Training epoch 0, iteration 75/499 | lr: 0.0009468 | global_batch_size: 8 | global_step: 75 | reduced_train_loss: 8.835 | consumed_samples: 608\n",
      "Training epoch 0, iteration 76/499 | lr: 0.0009453 | global_batch_size: 8 | global_step: 76 | reduced_train_loss: 9.061 | consumed_samples: 616\n",
      "Training epoch 0, iteration 77/499 | lr: 0.0009438 | global_batch_size: 8 | global_step: 77 | reduced_train_loss: 8.866 | consumed_samples: 624\n",
      "Training epoch 0, iteration 78/499 | lr: 0.0009422 | global_batch_size: 8 | global_step: 78 | reduced_train_loss: 8.981 | consumed_samples: 632\n",
      "Training epoch 0, iteration 79/499 | lr: 0.0009407 | global_batch_size: 8 | global_step: 79 | reduced_train_loss: 8.91 | consumed_samples: 640\n",
      "Training epoch 0, iteration 80/499 | lr: 0.0009391 | global_batch_size: 8 | global_step: 80 | reduced_train_loss: 8.661 | consumed_samples: 648\n",
      "Training epoch 0, iteration 81/499 | lr: 0.0009375 | global_batch_size: 8 | global_step: 81 | reduced_train_loss: 8.677 | consumed_samples: 656\n",
      "Training epoch 0, iteration 82/499 | lr: 0.0009359 | global_batch_size: 8 | global_step: 82 | reduced_train_loss: 8.889 | consumed_samples: 664\n",
      "Training epoch 0, iteration 83/499 | lr: 0.0009342 | global_batch_size: 8 | global_step: 83 | reduced_train_loss: 8.864 | consumed_samples: 672\n",
      "Training epoch 0, iteration 84/499 | lr: 0.0009326 | global_batch_size: 8 | global_step: 84 | reduced_train_loss: 8.712 | consumed_samples: 680\n",
      "Training epoch 0, iteration 85/499 | lr: 0.0009309 | global_batch_size: 8 | global_step: 85 | reduced_train_loss: 8.97 | consumed_samples: 688\n",
      "Training epoch 0, iteration 86/499 | lr: 0.0009292 | global_batch_size: 8 | global_step: 86 | reduced_train_loss: 8.945 | consumed_samples: 696\n",
      "Training epoch 0, iteration 87/499 | lr: 0.0009275 | global_batch_size: 8 | global_step: 87 | reduced_train_loss: 8.979 | consumed_samples: 704\n",
      "Training epoch 0, iteration 88/499 | lr: 0.0009258 | global_batch_size: 8 | global_step: 88 | reduced_train_loss: 8.766 | consumed_samples: 712\n",
      "Training epoch 0, iteration 89/499 | lr: 0.000924 | global_batch_size: 8 | global_step: 89 | reduced_train_loss: 8.86 | consumed_samples: 720\n",
      "Training epoch 0, iteration 90/499 | lr: 0.0009222 | global_batch_size: 8 | global_step: 90 | reduced_train_loss: 8.928 | consumed_samples: 728\n",
      "Training epoch 0, iteration 91/499 | lr: 0.0009204 | global_batch_size: 8 | global_step: 91 | reduced_train_loss: 8.563 | consumed_samples: 736\n",
      "Training epoch 0, iteration 92/499 | lr: 0.0009186 | global_batch_size: 8 | global_step: 92 | reduced_train_loss: 8.892 | consumed_samples: 744\n",
      "Training epoch 0, iteration 93/499 | lr: 0.0009168 | global_batch_size: 8 | global_step: 93 | reduced_train_loss: 8.851 | consumed_samples: 752\n",
      "Training epoch 0, iteration 94/499 | lr: 0.000915 | global_batch_size: 8 | global_step: 94 | reduced_train_loss: 8.94 | consumed_samples: 760\n",
      "Training epoch 0, iteration 95/499 | lr: 0.0009131 | global_batch_size: 8 | global_step: 95 | reduced_train_loss: 8.961 | consumed_samples: 768\n",
      "Training epoch 0, iteration 96/499 | lr: 0.0009112 | global_batch_size: 8 | global_step: 96 | reduced_train_loss: 8.927 | consumed_samples: 776\n",
      "Training epoch 0, iteration 97/499 | lr: 0.0009093 | global_batch_size: 8 | global_step: 97 | reduced_train_loss: 8.928 | consumed_samples: 784\n",
      "Training epoch 0, iteration 98/499 | lr: 0.0009074 | global_batch_size: 8 | global_step: 98 | reduced_train_loss: 8.887 | consumed_samples: 792\n",
      "Training epoch 0, iteration 99/499 | lr: 0.0009055 | global_batch_size: 8 | global_step: 99 | reduced_train_loss: 8.816 | consumed_samples: 800\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: Epoch 0, global step 99: 'reduced_train_loss' reached 8.81633 (best 8.81633), saving model to '/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=0.00-step=99-consumed_samples=800.0.ckpt' as top 2\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/transformer/transformer_layer.py:339: UserWarning: TransformerLayer._get_layer_offset is deprecated.Please use get_transformer_layer_offset instead.\n",
      "  warnings.warn(\n",
      "\n",
      "[NeMo I 2025-03-11 20:30:58 nemo_logging:393] Using FullyParallelSaveStrategyWrapper(torch_dist, 1) dist-ckpt save strategy.\n",
      "[NeMo W 2025-03-11 20:31:07 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[NeMo I 2025-03-11 20:31:10 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 99 : Start time: 1741725058.995s : Save duration: 11.516s\n",
      "[NeMo I 2025-03-11 20:31:13 nemo_logging:393] Scheduled async checkpoint save for /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=0.00-step=99-consumed_samples=800.0.ckpt\n",
      "[NeMo I 2025-03-11 20:31:13 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 99 : Start time: 1741725073.552s : Save duration: 0.050s\n",
      "[NeMo I 2025-03-11 20:31:16 nemo_logging:393] Scheduled async checkpoint save for /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=0.00-step=99-consumed_samples=800.0-last.ckpt\n",
      "[NeMo I 2025-03-11 20:31:16 nemo_logging:393] Successfully saved checkpoint from iteration      99 to /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=0.00-step=99-consumed_samples=800.0.ckpt\n",
      "[NeMo I 2025-03-11 20:31:16 nemo_logging:393] Async checkpoint save for step 100 (/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=0.00-step=99-consumed_samples=800.0.ckpt) finalized successfully.\n",
      "[NeMo I 2025-03-11 20:31:16 nemo_logging:393] Successfully saved checkpoint from iteration      99 to /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=0.00-step=99-consumed_samples=800.0-last.ckpt\n",
      "[NeMo I 2025-03-11 20:31:16 nemo_logging:393] Async checkpoint save for step 100 (/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=0.00-step=99-consumed_samples=800.0-last.ckpt) finalized successfully.\n",
      "[NeMo I 2025-03-11 20:31:16 nemo_logging:393] Async finalization time took 0.048 s\n",
      "Validation: iteration 1/2\n",
      "Validation: iteration 2/2\n",
      "Validation: iteration 3/2\n",
      "Validation: iteration 4/2\n",
      "Validation: iteration 5/2\n",
      "Validation: iteration 6/2\n",
      "Validation: iteration 7/2\n",
      "Validation: iteration 8/2\n",
      "Training epoch 0, iteration 100/499 | lr: 0.0009035 | global_batch_size: 8 | global_step: 100 | reduced_train_loss: 8.874 | consumed_samples: 808 | val_loss: 8.996\n",
      "Training epoch 0, iteration 101/499 | lr: 0.0009015 | global_batch_size: 8 | global_step: 101 | reduced_train_loss: 8.698 | consumed_samples: 816 | val_loss: 8.996\n",
      "Training epoch 0, iteration 102/499 | lr: 0.0008995 | global_batch_size: 8 | global_step: 102 | reduced_train_loss: 8.859 | consumed_samples: 824 | val_loss: 8.996\n",
      "Training epoch 0, iteration 103/499 | lr: 0.0008975 | global_batch_size: 8 | global_step: 103 | reduced_train_loss: 8.825 | consumed_samples: 832 | val_loss: 8.996\n",
      "Training epoch 0, iteration 104/499 | lr: 0.0008955 | global_batch_size: 8 | global_step: 104 | reduced_train_loss: 8.981 | consumed_samples: 840 | val_loss: 8.996\n",
      "Training epoch 0, iteration 105/499 | lr: 0.0008935 | global_batch_size: 8 | global_step: 105 | reduced_train_loss: 8.89 | consumed_samples: 848 | val_loss: 8.996\n",
      "Training epoch 0, iteration 106/499 | lr: 0.0008914 | global_batch_size: 8 | global_step: 106 | reduced_train_loss: 8.848 | consumed_samples: 856 | val_loss: 8.996\n",
      "Training epoch 0, iteration 107/499 | lr: 0.0008893 | global_batch_size: 8 | global_step: 107 | reduced_train_loss: 8.858 | consumed_samples: 864 | val_loss: 8.996\n",
      "Training epoch 0, iteration 108/499 | lr: 0.0008872 | global_batch_size: 8 | global_step: 108 | reduced_train_loss: 8.841 | consumed_samples: 872 | val_loss: 8.996\n",
      "Training epoch 0, iteration 109/499 | lr: 0.0008851 | global_batch_size: 8 | global_step: 109 | reduced_train_loss: 8.904 | consumed_samples: 880 | val_loss: 8.996\n",
      "Training epoch 0, iteration 110/499 | lr: 0.000883 | global_batch_size: 8 | global_step: 110 | reduced_train_loss: 8.881 | consumed_samples: 888 | val_loss: 8.996\n",
      "Training epoch 0, iteration 111/499 | lr: 0.0008809 | global_batch_size: 8 | global_step: 111 | reduced_train_loss: 8.785 | consumed_samples: 896 | val_loss: 8.996\n",
      "Training epoch 0, iteration 112/499 | lr: 0.0008787 | global_batch_size: 8 | global_step: 112 | reduced_train_loss: 8.718 | consumed_samples: 904 | val_loss: 8.996\n",
      "Training epoch 0, iteration 113/499 | lr: 0.0008765 | global_batch_size: 8 | global_step: 113 | reduced_train_loss: 8.827 | consumed_samples: 912 | val_loss: 8.996\n",
      "Training epoch 0, iteration 114/499 | lr: 0.0008743 | global_batch_size: 8 | global_step: 114 | reduced_train_loss: 8.746 | consumed_samples: 920 | val_loss: 8.996\n",
      "Training epoch 0, iteration 115/499 | lr: 0.0008721 | global_batch_size: 8 | global_step: 115 | reduced_train_loss: 8.902 | consumed_samples: 928 | val_loss: 8.996\n",
      "Training epoch 0, iteration 116/499 | lr: 0.0008699 | global_batch_size: 8 | global_step: 116 | reduced_train_loss: 8.507 | consumed_samples: 936 | val_loss: 8.996\n",
      "Training epoch 0, iteration 117/499 | lr: 0.0008676 | global_batch_size: 8 | global_step: 117 | reduced_train_loss: 8.645 | consumed_samples: 944 | val_loss: 8.996\n",
      "Training epoch 0, iteration 118/499 | lr: 0.0008654 | global_batch_size: 8 | global_step: 118 | reduced_train_loss: 8.812 | consumed_samples: 952 | val_loss: 8.996\n",
      "Training epoch 0, iteration 119/499 | lr: 0.0008631 | global_batch_size: 8 | global_step: 119 | reduced_train_loss: 8.86 | consumed_samples: 960 | val_loss: 8.996\n",
      "Training epoch 0, iteration 120/499 | lr: 0.0008608 | global_batch_size: 8 | global_step: 120 | reduced_train_loss: 8.89 | consumed_samples: 968 | val_loss: 8.996\n",
      "Training epoch 0, iteration 121/499 | lr: 0.0008585 | global_batch_size: 8 | global_step: 121 | reduced_train_loss: 8.709 | consumed_samples: 976 | val_loss: 8.996\n",
      "Training epoch 0, iteration 122/499 | lr: 0.0008562 | global_batch_size: 8 | global_step: 122 | reduced_train_loss: 9.014 | consumed_samples: 984 | val_loss: 8.996\n",
      "Training epoch 0, iteration 123/499 | lr: 0.0008538 | global_batch_size: 8 | global_step: 123 | reduced_train_loss: 8.737 | consumed_samples: 992 | val_loss: 8.996\n",
      "Training epoch 0, iteration 124/499 | lr: 0.0008515 | global_batch_size: 8 | global_step: 124 | reduced_train_loss: 8.687 | consumed_samples: 1000 | val_loss: 8.996\n",
      "Training epoch 0, iteration 125/499 | lr: 0.0008491 | global_batch_size: 8 | global_step: 125 | reduced_train_loss: 8.77 | consumed_samples: 1008 | val_loss: 8.996\n",
      "Training epoch 0, iteration 126/499 | lr: 0.0008467 | global_batch_size: 8 | global_step: 126 | reduced_train_loss: 8.628 | consumed_samples: 1016 | val_loss: 8.996\n",
      "Training epoch 0, iteration 127/499 | lr: 0.0008443 | global_batch_size: 8 | global_step: 127 | reduced_train_loss: 8.718 | consumed_samples: 1024 | val_loss: 8.996\n",
      "Training epoch 0, iteration 128/499 | lr: 0.0008419 | global_batch_size: 8 | global_step: 128 | reduced_train_loss: 8.777 | consumed_samples: 1032 | val_loss: 8.996\n",
      "Training epoch 0, iteration 129/499 | lr: 0.0008395 | global_batch_size: 8 | global_step: 129 | reduced_train_loss: 8.786 | consumed_samples: 1040 | val_loss: 8.996\n",
      "Training epoch 0, iteration 130/499 | lr: 0.000837 | global_batch_size: 8 | global_step: 130 | reduced_train_loss: 8.79 | consumed_samples: 1048 | val_loss: 8.996\n",
      "Training epoch 0, iteration 131/499 | lr: 0.0008346 | global_batch_size: 8 | global_step: 131 | reduced_train_loss: 8.72 | consumed_samples: 1056 | val_loss: 8.996\n",
      "Training epoch 0, iteration 132/499 | lr: 0.0008321 | global_batch_size: 8 | global_step: 132 | reduced_train_loss: 8.834 | consumed_samples: 1064 | val_loss: 8.996\n",
      "Training epoch 0, iteration 133/499 | lr: 0.0008296 | global_batch_size: 8 | global_step: 133 | reduced_train_loss: 8.801 | consumed_samples: 1072 | val_loss: 8.996\n",
      "Training epoch 0, iteration 134/499 | lr: 0.0008271 | global_batch_size: 8 | global_step: 134 | reduced_train_loss: 8.897 | consumed_samples: 1080 | val_loss: 8.996\n",
      "Training epoch 0, iteration 135/499 | lr: 0.0008246 | global_batch_size: 8 | global_step: 135 | reduced_train_loss: 8.705 | consumed_samples: 1088 | val_loss: 8.996\n",
      "Training epoch 0, iteration 136/499 | lr: 0.0008221 | global_batch_size: 8 | global_step: 136 | reduced_train_loss: 8.761 | consumed_samples: 1096 | val_loss: 8.996\n",
      "Training epoch 0, iteration 137/499 | lr: 0.0008195 | global_batch_size: 8 | global_step: 137 | reduced_train_loss: 8.762 | consumed_samples: 1104 | val_loss: 8.996\n",
      "Training epoch 0, iteration 138/499 | lr: 0.0008169 | global_batch_size: 8 | global_step: 138 | reduced_train_loss: 8.767 | consumed_samples: 1112 | val_loss: 8.996\n",
      "Training epoch 0, iteration 139/499 | lr: 0.0008144 | global_batch_size: 8 | global_step: 139 | reduced_train_loss: 8.737 | consumed_samples: 1120 | val_loss: 8.996\n",
      "Training epoch 0, iteration 140/499 | lr: 0.0008118 | global_batch_size: 8 | global_step: 140 | reduced_train_loss: 8.767 | consumed_samples: 1128 | val_loss: 8.996\n",
      "Training epoch 0, iteration 141/499 | lr: 0.0008092 | global_batch_size: 8 | global_step: 141 | reduced_train_loss: 8.763 | consumed_samples: 1136 | val_loss: 8.996\n",
      "Training epoch 0, iteration 142/499 | lr: 0.0008066 | global_batch_size: 8 | global_step: 142 | reduced_train_loss: 8.752 | consumed_samples: 1144 | val_loss: 8.996\n",
      "Training epoch 0, iteration 143/499 | lr: 0.0008039 | global_batch_size: 8 | global_step: 143 | reduced_train_loss: 8.763 | consumed_samples: 1152 | val_loss: 8.996\n",
      "Training epoch 0, iteration 144/499 | lr: 0.0008013 | global_batch_size: 8 | global_step: 144 | reduced_train_loss: 8.75 | consumed_samples: 1160 | val_loss: 8.996\n",
      "Training epoch 0, iteration 145/499 | lr: 0.0007986 | global_batch_size: 8 | global_step: 145 | reduced_train_loss: 8.859 | consumed_samples: 1168 | val_loss: 8.996\n",
      "Training epoch 0, iteration 146/499 | lr: 0.000796 | global_batch_size: 8 | global_step: 146 | reduced_train_loss: 8.851 | consumed_samples: 1176 | val_loss: 8.996\n",
      "Training epoch 0, iteration 147/499 | lr: 0.0007933 | global_batch_size: 8 | global_step: 147 | reduced_train_loss: 8.772 | consumed_samples: 1184 | val_loss: 8.996\n",
      "Training epoch 0, iteration 148/499 | lr: 0.0007906 | global_batch_size: 8 | global_step: 148 | reduced_train_loss: 8.784 | consumed_samples: 1192 | val_loss: 8.996\n",
      "Training epoch 0, iteration 149/499 | lr: 0.0007879 | global_batch_size: 8 | global_step: 149 | reduced_train_loss: 8.637 | consumed_samples: 1200 | val_loss: 8.996\n",
      "Training epoch 0, iteration 150/499 | lr: 0.0007851 | global_batch_size: 8 | global_step: 150 | reduced_train_loss: 8.702 | consumed_samples: 1208 | val_loss: 8.996\n",
      "Training epoch 0, iteration 151/499 | lr: 0.0007824 | global_batch_size: 8 | global_step: 151 | reduced_train_loss: 8.524 | consumed_samples: 1216 | val_loss: 8.996\n",
      "Training epoch 0, iteration 152/499 | lr: 0.0007797 | global_batch_size: 8 | global_step: 152 | reduced_train_loss: 8.797 | consumed_samples: 1224 | val_loss: 8.996\n",
      "Training epoch 0, iteration 153/499 | lr: 0.0007769 | global_batch_size: 8 | global_step: 153 | reduced_train_loss: 8.727 | consumed_samples: 1232 | val_loss: 8.996\n",
      "Training epoch 0, iteration 154/499 | lr: 0.0007741 | global_batch_size: 8 | global_step: 154 | reduced_train_loss: 8.757 | consumed_samples: 1240 | val_loss: 8.996\n",
      "Training epoch 0, iteration 155/499 | lr: 0.0007714 | global_batch_size: 8 | global_step: 155 | reduced_train_loss: 8.768 | consumed_samples: 1248 | val_loss: 8.996\n",
      "Training epoch 0, iteration 156/499 | lr: 0.0007686 | global_batch_size: 8 | global_step: 156 | reduced_train_loss: 8.805 | consumed_samples: 1256 | val_loss: 8.996\n",
      "Training epoch 0, iteration 157/499 | lr: 0.0007657 | global_batch_size: 8 | global_step: 157 | reduced_train_loss: 8.787 | consumed_samples: 1264 | val_loss: 8.996\n",
      "Training epoch 0, iteration 158/499 | lr: 0.0007629 | global_batch_size: 8 | global_step: 158 | reduced_train_loss: 8.684 | consumed_samples: 1272 | val_loss: 8.996\n",
      "Training epoch 0, iteration 159/499 | lr: 0.0007601 | global_batch_size: 8 | global_step: 159 | reduced_train_loss: 8.518 | consumed_samples: 1280 | val_loss: 8.996\n",
      "Training epoch 0, iteration 160/499 | lr: 0.0007573 | global_batch_size: 8 | global_step: 160 | reduced_train_loss: 8.745 | consumed_samples: 1288 | val_loss: 8.996\n",
      "Training epoch 0, iteration 161/499 | lr: 0.0007544 | global_batch_size: 8 | global_step: 161 | reduced_train_loss: 8.697 | consumed_samples: 1296 | val_loss: 8.996\n",
      "Training epoch 0, iteration 162/499 | lr: 0.0007515 | global_batch_size: 8 | global_step: 162 | reduced_train_loss: 8.616 | consumed_samples: 1304 | val_loss: 8.996\n",
      "Training epoch 0, iteration 163/499 | lr: 0.0007487 | global_batch_size: 8 | global_step: 163 | reduced_train_loss: 8.707 | consumed_samples: 1312 | val_loss: 8.996\n",
      "Training epoch 0, iteration 164/499 | lr: 0.0007458 | global_batch_size: 8 | global_step: 164 | reduced_train_loss: 8.794 | consumed_samples: 1320 | val_loss: 8.996\n",
      "Training epoch 0, iteration 165/499 | lr: 0.0007429 | global_batch_size: 8 | global_step: 165 | reduced_train_loss: 8.714 | consumed_samples: 1328 | val_loss: 8.996\n",
      "Training epoch 0, iteration 166/499 | lr: 0.00074 | global_batch_size: 8 | global_step: 166 | reduced_train_loss: 8.735 | consumed_samples: 1336 | val_loss: 8.996\n",
      "Training epoch 0, iteration 167/499 | lr: 0.0007371 | global_batch_size: 8 | global_step: 167 | reduced_train_loss: 8.578 | consumed_samples: 1344 | val_loss: 8.996\n",
      "Training epoch 0, iteration 168/499 | lr: 0.0007341 | global_batch_size: 8 | global_step: 168 | reduced_train_loss: 8.877 | consumed_samples: 1352 | val_loss: 8.996\n",
      "Training epoch 0, iteration 169/499 | lr: 0.0007312 | global_batch_size: 8 | global_step: 169 | reduced_train_loss: 8.65 | consumed_samples: 1360 | val_loss: 8.996\n",
      "Training epoch 0, iteration 170/499 | lr: 0.0007283 | global_batch_size: 8 | global_step: 170 | reduced_train_loss: 8.895 | consumed_samples: 1368 | val_loss: 8.996\n",
      "Training epoch 0, iteration 171/499 | lr: 0.0007253 | global_batch_size: 8 | global_step: 171 | reduced_train_loss: 8.821 | consumed_samples: 1376 | val_loss: 8.996\n",
      "Training epoch 0, iteration 172/499 | lr: 0.0007223 | global_batch_size: 8 | global_step: 172 | reduced_train_loss: 8.754 | consumed_samples: 1384 | val_loss: 8.996\n",
      "Training epoch 0, iteration 173/499 | lr: 0.0007193 | global_batch_size: 8 | global_step: 173 | reduced_train_loss: 8.696 | consumed_samples: 1392 | val_loss: 8.996\n",
      "Training epoch 0, iteration 174/499 | lr: 0.0007164 | global_batch_size: 8 | global_step: 174 | reduced_train_loss: 8.816 | consumed_samples: 1400 | val_loss: 8.996\n",
      "Training epoch 0, iteration 175/499 | lr: 0.0007134 | global_batch_size: 8 | global_step: 175 | reduced_train_loss: 8.761 | consumed_samples: 1408 | val_loss: 8.996\n",
      "Training epoch 0, iteration 176/499 | lr: 0.0007104 | global_batch_size: 8 | global_step: 176 | reduced_train_loss: 8.411 | consumed_samples: 1416 | val_loss: 8.996\n",
      "Training epoch 0, iteration 177/499 | lr: 0.0007073 | global_batch_size: 8 | global_step: 177 | reduced_train_loss: 8.532 | consumed_samples: 1424 | val_loss: 8.996\n",
      "Training epoch 0, iteration 178/499 | lr: 0.0007043 | global_batch_size: 8 | global_step: 178 | reduced_train_loss: 8.684 | consumed_samples: 1432 | val_loss: 8.996\n",
      "Training epoch 0, iteration 179/499 | lr: 0.0007013 | global_batch_size: 8 | global_step: 179 | reduced_train_loss: 8.628 | consumed_samples: 1440 | val_loss: 8.996\n",
      "Training epoch 0, iteration 180/499 | lr: 0.0006982 | global_batch_size: 8 | global_step: 180 | reduced_train_loss: 8.808 | consumed_samples: 1448 | val_loss: 8.996\n",
      "Training epoch 0, iteration 181/499 | lr: 0.0006952 | global_batch_size: 8 | global_step: 181 | reduced_train_loss: 8.668 | consumed_samples: 1456 | val_loss: 8.996\n",
      "Training epoch 0, iteration 182/499 | lr: 0.0006921 | global_batch_size: 8 | global_step: 182 | reduced_train_loss: 8.677 | consumed_samples: 1464 | val_loss: 8.996\n",
      "Training epoch 0, iteration 183/499 | lr: 0.0006891 | global_batch_size: 8 | global_step: 183 | reduced_train_loss: 8.744 | consumed_samples: 1472 | val_loss: 8.996\n",
      "Training epoch 0, iteration 184/499 | lr: 0.000686 | global_batch_size: 8 | global_step: 184 | reduced_train_loss: 8.445 | consumed_samples: 1480 | val_loss: 8.996\n",
      "Training epoch 0, iteration 185/499 | lr: 0.0006829 | global_batch_size: 8 | global_step: 185 | reduced_train_loss: 8.605 | consumed_samples: 1488 | val_loss: 8.996\n",
      "Training epoch 0, iteration 186/499 | lr: 0.0006798 | global_batch_size: 8 | global_step: 186 | reduced_train_loss: 8.701 | consumed_samples: 1496 | val_loss: 8.996\n",
      "Training epoch 0, iteration 187/499 | lr: 0.0006767 | global_batch_size: 8 | global_step: 187 | reduced_train_loss: 8.774 | consumed_samples: 1504 | val_loss: 8.996\n",
      "Training epoch 0, iteration 188/499 | lr: 0.0006736 | global_batch_size: 8 | global_step: 188 | reduced_train_loss: 8.406 | consumed_samples: 1512 | val_loss: 8.996\n",
      "Training epoch 0, iteration 189/499 | lr: 0.0006705 | global_batch_size: 8 | global_step: 189 | reduced_train_loss: 8.471 | consumed_samples: 1520 | val_loss: 8.996\n",
      "Training epoch 0, iteration 190/499 | lr: 0.0006674 | global_batch_size: 8 | global_step: 190 | reduced_train_loss: 8.52 | consumed_samples: 1528 | val_loss: 8.996\n",
      "Training epoch 0, iteration 191/499 | lr: 0.0006642 | global_batch_size: 8 | global_step: 191 | reduced_train_loss: 8.649 | consumed_samples: 1536 | val_loss: 8.996\n",
      "Training epoch 0, iteration 192/499 | lr: 0.0006611 | global_batch_size: 8 | global_step: 192 | reduced_train_loss: 8.708 | consumed_samples: 1544 | val_loss: 8.996\n",
      "Training epoch 0, iteration 193/499 | lr: 0.000658 | global_batch_size: 8 | global_step: 193 | reduced_train_loss: 8.686 | consumed_samples: 1552 | val_loss: 8.996\n",
      "Training epoch 0, iteration 194/499 | lr: 0.0006548 | global_batch_size: 8 | global_step: 194 | reduced_train_loss: 8.659 | consumed_samples: 1560 | val_loss: 8.996\n",
      "Training epoch 0, iteration 195/499 | lr: 0.0006517 | global_batch_size: 8 | global_step: 195 | reduced_train_loss: 8.589 | consumed_samples: 1568 | val_loss: 8.996\n",
      "Training epoch 0, iteration 196/499 | lr: 0.0006485 | global_batch_size: 8 | global_step: 196 | reduced_train_loss: 8.588 | consumed_samples: 1576 | val_loss: 8.996\n",
      "Training epoch 0, iteration 197/499 | lr: 0.0006453 | global_batch_size: 8 | global_step: 197 | reduced_train_loss: 8.663 | consumed_samples: 1584 | val_loss: 8.996\n",
      "Training epoch 0, iteration 198/499 | lr: 0.0006421 | global_batch_size: 8 | global_step: 198 | reduced_train_loss: 8.551 | consumed_samples: 1592 | val_loss: 8.996\n",
      "Training epoch 0, iteration 199/499 | lr: 0.000639 | global_batch_size: 8 | global_step: 199 | reduced_train_loss: 8.745 | consumed_samples: 1600 | val_loss: 8.996\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: Epoch 0, global step 199: 'reduced_train_loss' reached 8.74529 (best 8.74529), saving model to '/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=9.00-step=199-consumed_samples=1600.0.ckpt' as top 2\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/transformer/transformer_layer.py:339: UserWarning: TransformerLayer._get_layer_offset is deprecated.Please use get_transformer_layer_offset instead.\n",
      "  warnings.warn(\n",
      "\n",
      "[NeMo I 2025-03-11 20:31:25 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 199 : Start time: 1741725085.450s : Save duration: 0.052s\n",
      "[NeMo I 2025-03-11 20:31:28 nemo_logging:393] Scheduled async checkpoint save for /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=9.00-step=199-consumed_samples=1600.0.ckpt\n",
      "[NeMo I 2025-03-11 20:31:28 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 199 : Start time: 1741725088.561s : Save duration: 0.052s\n",
      "[NeMo I 2025-03-11 20:31:31 nemo_logging:393] Scheduled async checkpoint save for /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=9.00-step=199-consumed_samples=1600.0-last.ckpt\n",
      "[NeMo I 2025-03-11 20:31:31 nemo_logging:393] Successfully saved checkpoint from iteration     199 to /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=9.00-step=199-consumed_samples=1600.0.ckpt\n",
      "[NeMo I 2025-03-11 20:31:31 nemo_logging:393] Async checkpoint save for step 200 (/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=9.00-step=199-consumed_samples=1600.0.ckpt) finalized successfully.\n",
      "[NeMo I 2025-03-11 20:31:31 nemo_logging:393] Successfully saved checkpoint from iteration     199 to /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=9.00-step=199-consumed_samples=1600.0-last.ckpt\n",
      "[NeMo I 2025-03-11 20:31:31 nemo_logging:393] Async checkpoint save for step 200 (/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=9.00-step=199-consumed_samples=1600.0-last.ckpt) finalized successfully.\n",
      "[NeMo I 2025-03-11 20:31:31 nemo_logging:393] Async finalization time took 0.073 s\n",
      "Validation: iteration 1/2\n",
      "Validation: iteration 2/2\n",
      "Validation: iteration 3/2\n",
      "Validation: iteration 4/2\n",
      "Validation: iteration 5/2\n",
      "Validation: iteration 6/2\n",
      "Validation: iteration 7/2\n",
      "Validation: iteration 8/2\n",
      "Training epoch 0, iteration 200/499 | lr: 0.0006358 | global_batch_size: 8 | global_step: 200 | reduced_train_loss: 8.536 | consumed_samples: 1608 | val_loss: 8.654\n",
      "Training epoch 0, iteration 201/499 | lr: 0.0006326 | global_batch_size: 8 | global_step: 201 | reduced_train_loss: 8.639 | consumed_samples: 1616 | val_loss: 8.654\n",
      "Training epoch 0, iteration 202/499 | lr: 0.0006294 | global_batch_size: 8 | global_step: 202 | reduced_train_loss: 8.474 | consumed_samples: 1624 | val_loss: 8.654\n",
      "Training epoch 0, iteration 203/499 | lr: 0.0006262 | global_batch_size: 8 | global_step: 203 | reduced_train_loss: 8.569 | consumed_samples: 1632 | val_loss: 8.654\n",
      "Training epoch 0, iteration 204/499 | lr: 0.000623 | global_batch_size: 8 | global_step: 204 | reduced_train_loss: 8.602 | consumed_samples: 1640 | val_loss: 8.654\n",
      "Training epoch 0, iteration 205/499 | lr: 0.0006198 | global_batch_size: 8 | global_step: 205 | reduced_train_loss: 8.558 | consumed_samples: 1648 | val_loss: 8.654\n",
      "Training epoch 0, iteration 206/499 | lr: 0.0006165 | global_batch_size: 8 | global_step: 206 | reduced_train_loss: 8.558 | consumed_samples: 1656 | val_loss: 8.654\n",
      "Training epoch 0, iteration 207/499 | lr: 0.0006133 | global_batch_size: 8 | global_step: 207 | reduced_train_loss: 8.734 | consumed_samples: 1664 | val_loss: 8.654\n",
      "Training epoch 0, iteration 208/499 | lr: 0.0006101 | global_batch_size: 8 | global_step: 208 | reduced_train_loss: 8.554 | consumed_samples: 1672 | val_loss: 8.654\n",
      "Training epoch 0, iteration 209/499 | lr: 0.0006068 | global_batch_size: 8 | global_step: 209 | reduced_train_loss: 8.573 | consumed_samples: 1680 | val_loss: 8.654\n",
      "Training epoch 0, iteration 210/499 | lr: 0.0006036 | global_batch_size: 8 | global_step: 210 | reduced_train_loss: 8.756 | consumed_samples: 1688 | val_loss: 8.654\n",
      "Training epoch 0, iteration 211/499 | lr: 0.0006004 | global_batch_size: 8 | global_step: 211 | reduced_train_loss: 8.879 | consumed_samples: 1696 | val_loss: 8.654\n",
      "Training epoch 0, iteration 212/499 | lr: 0.0005971 | global_batch_size: 8 | global_step: 212 | reduced_train_loss: 8.627 | consumed_samples: 1704 | val_loss: 8.654\n",
      "Training epoch 0, iteration 213/499 | lr: 0.0005939 | global_batch_size: 8 | global_step: 213 | reduced_train_loss: 8.534 | consumed_samples: 1712 | val_loss: 8.654\n",
      "Training epoch 0, iteration 214/499 | lr: 0.0005906 | global_batch_size: 8 | global_step: 214 | reduced_train_loss: 8.522 | consumed_samples: 1720 | val_loss: 8.654\n",
      "Training epoch 0, iteration 215/499 | lr: 0.0005873 | global_batch_size: 8 | global_step: 215 | reduced_train_loss: 8.634 | consumed_samples: 1728 | val_loss: 8.654\n",
      "Training epoch 0, iteration 216/499 | lr: 0.0005841 | global_batch_size: 8 | global_step: 216 | reduced_train_loss: 8.584 | consumed_samples: 1736 | val_loss: 8.654\n",
      "Training epoch 0, iteration 217/499 | lr: 0.0005808 | global_batch_size: 8 | global_step: 217 | reduced_train_loss: 8.55 | consumed_samples: 1744 | val_loss: 8.654\n",
      "Training epoch 0, iteration 218/499 | lr: 0.0005775 | global_batch_size: 8 | global_step: 218 | reduced_train_loss: 8.553 | consumed_samples: 1752 | val_loss: 8.654\n",
      "Training epoch 0, iteration 219/499 | lr: 0.0005743 | global_batch_size: 8 | global_step: 219 | reduced_train_loss: 8.617 | consumed_samples: 1760 | val_loss: 8.654\n",
      "Training epoch 0, iteration 220/499 | lr: 0.000571 | global_batch_size: 8 | global_step: 220 | reduced_train_loss: 8.647 | consumed_samples: 1768 | val_loss: 8.654\n",
      "Training epoch 0, iteration 221/499 | lr: 0.0005677 | global_batch_size: 8 | global_step: 221 | reduced_train_loss: 8.698 | consumed_samples: 1776 | val_loss: 8.654\n",
      "Training epoch 0, iteration 222/499 | lr: 0.0005644 | global_batch_size: 8 | global_step: 222 | reduced_train_loss: 8.655 | consumed_samples: 1784 | val_loss: 8.654\n",
      "Training epoch 0, iteration 223/499 | lr: 0.0005611 | global_batch_size: 8 | global_step: 223 | reduced_train_loss: 8.578 | consumed_samples: 1792 | val_loss: 8.654\n",
      "Training epoch 0, iteration 224/499 | lr: 0.0005578 | global_batch_size: 8 | global_step: 224 | reduced_train_loss: 8.612 | consumed_samples: 1800 | val_loss: 8.654\n",
      "Training epoch 0, iteration 225/499 | lr: 0.0005545 | global_batch_size: 8 | global_step: 225 | reduced_train_loss: 8.533 | consumed_samples: 1808 | val_loss: 8.654\n",
      "Training epoch 0, iteration 226/499 | lr: 0.0005513 | global_batch_size: 8 | global_step: 226 | reduced_train_loss: 8.62 | consumed_samples: 1816 | val_loss: 8.654\n",
      "Training epoch 0, iteration 227/499 | lr: 0.000548 | global_batch_size: 8 | global_step: 227 | reduced_train_loss: 8.335 | consumed_samples: 1824 | val_loss: 8.654\n",
      "Training epoch 0, iteration 228/499 | lr: 0.0005447 | global_batch_size: 8 | global_step: 228 | reduced_train_loss: 8.584 | consumed_samples: 1832 | val_loss: 8.654\n",
      "Training epoch 0, iteration 229/499 | lr: 0.0005414 | global_batch_size: 8 | global_step: 229 | reduced_train_loss: 8.636 | consumed_samples: 1840 | val_loss: 8.654\n",
      "Training epoch 0, iteration 230/499 | lr: 0.0005381 | global_batch_size: 8 | global_step: 230 | reduced_train_loss: 8.377 | consumed_samples: 1848 | val_loss: 8.654\n",
      "Training epoch 0, iteration 231/499 | lr: 0.0005348 | global_batch_size: 8 | global_step: 231 | reduced_train_loss: 8.669 | consumed_samples: 1856 | val_loss: 8.654\n",
      "Training epoch 0, iteration 232/499 | lr: 0.0005315 | global_batch_size: 8 | global_step: 232 | reduced_train_loss: 8.668 | consumed_samples: 1864 | val_loss: 8.654\n",
      "Training epoch 0, iteration 233/499 | lr: 0.0005282 | global_batch_size: 8 | global_step: 233 | reduced_train_loss: 8.537 | consumed_samples: 1872 | val_loss: 8.654\n",
      "Training epoch 0, iteration 234/499 | lr: 0.0005248 | global_batch_size: 8 | global_step: 234 | reduced_train_loss: 8.463 | consumed_samples: 1880 | val_loss: 8.654\n",
      "Training epoch 0, iteration 235/499 | lr: 0.0005215 | global_batch_size: 8 | global_step: 235 | reduced_train_loss: 8.401 | consumed_samples: 1888 | val_loss: 8.654\n",
      "Training epoch 0, iteration 236/499 | lr: 0.0005182 | global_batch_size: 8 | global_step: 236 | reduced_train_loss: 8.504 | consumed_samples: 1896 | val_loss: 8.654\n",
      "Training epoch 0, iteration 237/499 | lr: 0.0005149 | global_batch_size: 8 | global_step: 237 | reduced_train_loss: 8.512 | consumed_samples: 1904 | val_loss: 8.654\n",
      "Training epoch 0, iteration 238/499 | lr: 0.0005116 | global_batch_size: 8 | global_step: 238 | reduced_train_loss: 8.405 | consumed_samples: 1912 | val_loss: 8.654\n",
      "Training epoch 0, iteration 239/499 | lr: 0.0005083 | global_batch_size: 8 | global_step: 239 | reduced_train_loss: 8.407 | consumed_samples: 1920 | val_loss: 8.654\n",
      "Training epoch 0, iteration 240/499 | lr: 0.000505 | global_batch_size: 8 | global_step: 240 | reduced_train_loss: 8.565 | consumed_samples: 1928 | val_loss: 8.654\n",
      "Training epoch 0, iteration 241/499 | lr: 0.0005017 | global_batch_size: 8 | global_step: 241 | reduced_train_loss: 8.495 | consumed_samples: 1936 | val_loss: 8.654\n",
      "Training epoch 0, iteration 242/499 | lr: 0.0004984 | global_batch_size: 8 | global_step: 242 | reduced_train_loss: 8.532 | consumed_samples: 1944 | val_loss: 8.654\n",
      "Training epoch 0, iteration 243/499 | lr: 0.0004951 | global_batch_size: 8 | global_step: 243 | reduced_train_loss: 8.517 | consumed_samples: 1952 | val_loss: 8.654\n",
      "Training epoch 0, iteration 244/499 | lr: 0.0004918 | global_batch_size: 8 | global_step: 244 | reduced_train_loss: 8.572 | consumed_samples: 1960 | val_loss: 8.654\n",
      "Training epoch 0, iteration 245/499 | lr: 0.0004885 | global_batch_size: 8 | global_step: 245 | reduced_train_loss: 8.539 | consumed_samples: 1968 | val_loss: 8.654\n",
      "Training epoch 0, iteration 246/499 | lr: 0.0004852 | global_batch_size: 8 | global_step: 246 | reduced_train_loss: 8.594 | consumed_samples: 1976 | val_loss: 8.654\n",
      "Training epoch 0, iteration 247/499 | lr: 0.0004818 | global_batch_size: 8 | global_step: 247 | reduced_train_loss: 8.521 | consumed_samples: 1984 | val_loss: 8.654\n",
      "Training epoch 0, iteration 248/499 | lr: 0.0004785 | global_batch_size: 8 | global_step: 248 | reduced_train_loss: 8.543 | consumed_samples: 1992 | val_loss: 8.654\n",
      "Training epoch 0, iteration 249/499 | lr: 0.0004752 | global_batch_size: 8 | global_step: 249 | reduced_train_loss: 8.5 | consumed_samples: 2000 | val_loss: 8.654\n",
      "Training epoch 0, iteration 250/499 | lr: 0.0004719 | global_batch_size: 8 | global_step: 250 | reduced_train_loss: 8.494 | consumed_samples: 2008 | val_loss: 8.654\n",
      "Training epoch 0, iteration 251/499 | lr: 0.0004686 | global_batch_size: 8 | global_step: 251 | reduced_train_loss: 8.763 | consumed_samples: 2016 | val_loss: 8.654\n",
      "Training epoch 0, iteration 252/499 | lr: 0.0004653 | global_batch_size: 8 | global_step: 252 | reduced_train_loss: 8.454 | consumed_samples: 2024 | val_loss: 8.654\n",
      "Training epoch 0, iteration 253/499 | lr: 0.000462 | global_batch_size: 8 | global_step: 253 | reduced_train_loss: 8.443 | consumed_samples: 2032 | val_loss: 8.654\n",
      "Training epoch 0, iteration 254/499 | lr: 0.0004587 | global_batch_size: 8 | global_step: 254 | reduced_train_loss: 8.373 | consumed_samples: 2040 | val_loss: 8.654\n",
      "Training epoch 0, iteration 255/499 | lr: 0.0004555 | global_batch_size: 8 | global_step: 255 | reduced_train_loss: 8.615 | consumed_samples: 2048 | val_loss: 8.654\n",
      "Training epoch 0, iteration 256/499 | lr: 0.0004522 | global_batch_size: 8 | global_step: 256 | reduced_train_loss: 8.408 | consumed_samples: 2056 | val_loss: 8.654\n",
      "Training epoch 0, iteration 257/499 | lr: 0.0004489 | global_batch_size: 8 | global_step: 257 | reduced_train_loss: 8.483 | consumed_samples: 2064 | val_loss: 8.654\n",
      "Training epoch 0, iteration 258/499 | lr: 0.0004456 | global_batch_size: 8 | global_step: 258 | reduced_train_loss: 8.558 | consumed_samples: 2072 | val_loss: 8.654\n",
      "Training epoch 0, iteration 259/499 | lr: 0.0004423 | global_batch_size: 8 | global_step: 259 | reduced_train_loss: 8.492 | consumed_samples: 2080 | val_loss: 8.654\n",
      "Training epoch 0, iteration 260/499 | lr: 0.000439 | global_batch_size: 8 | global_step: 260 | reduced_train_loss: 8.471 | consumed_samples: 2088 | val_loss: 8.654\n",
      "Training epoch 0, iteration 261/499 | lr: 0.0004357 | global_batch_size: 8 | global_step: 261 | reduced_train_loss: 8.65 | consumed_samples: 2096 | val_loss: 8.654\n",
      "Training epoch 0, iteration 262/499 | lr: 0.0004325 | global_batch_size: 8 | global_step: 262 | reduced_train_loss: 8.322 | consumed_samples: 2104 | val_loss: 8.654\n",
      "Training epoch 0, iteration 263/499 | lr: 0.0004292 | global_batch_size: 8 | global_step: 263 | reduced_train_loss: 8.627 | consumed_samples: 2112 | val_loss: 8.654\n",
      "Training epoch 0, iteration 264/499 | lr: 0.0004259 | global_batch_size: 8 | global_step: 264 | reduced_train_loss: 8.51 | consumed_samples: 2120 | val_loss: 8.654\n",
      "Training epoch 0, iteration 265/499 | lr: 0.0004227 | global_batch_size: 8 | global_step: 265 | reduced_train_loss: 8.568 | consumed_samples: 2128 | val_loss: 8.654\n",
      "Training epoch 0, iteration 266/499 | lr: 0.0004194 | global_batch_size: 8 | global_step: 266 | reduced_train_loss: 8.372 | consumed_samples: 2136 | val_loss: 8.654\n",
      "Training epoch 0, iteration 267/499 | lr: 0.0004161 | global_batch_size: 8 | global_step: 267 | reduced_train_loss: 8.684 | consumed_samples: 2144 | val_loss: 8.654\n",
      "Training epoch 0, iteration 268/499 | lr: 0.0004129 | global_batch_size: 8 | global_step: 268 | reduced_train_loss: 8.702 | consumed_samples: 2152 | val_loss: 8.654\n",
      "Training epoch 0, iteration 269/499 | lr: 0.0004096 | global_batch_size: 8 | global_step: 269 | reduced_train_loss: 8.525 | consumed_samples: 2160 | val_loss: 8.654\n",
      "Training epoch 0, iteration 270/499 | lr: 0.0004064 | global_batch_size: 8 | global_step: 270 | reduced_train_loss: 8.479 | consumed_samples: 2168 | val_loss: 8.654\n",
      "Training epoch 0, iteration 271/499 | lr: 0.0004032 | global_batch_size: 8 | global_step: 271 | reduced_train_loss: 8.5 | consumed_samples: 2176 | val_loss: 8.654\n",
      "Training epoch 0, iteration 272/499 | lr: 0.0003999 | global_batch_size: 8 | global_step: 272 | reduced_train_loss: 8.512 | consumed_samples: 2184 | val_loss: 8.654\n",
      "Training epoch 0, iteration 273/499 | lr: 0.0003967 | global_batch_size: 8 | global_step: 273 | reduced_train_loss: 8.399 | consumed_samples: 2192 | val_loss: 8.654\n",
      "Training epoch 0, iteration 274/499 | lr: 0.0003935 | global_batch_size: 8 | global_step: 274 | reduced_train_loss: 8.389 | consumed_samples: 2200 | val_loss: 8.654\n",
      "Training epoch 0, iteration 275/499 | lr: 0.0003902 | global_batch_size: 8 | global_step: 275 | reduced_train_loss: 8.437 | consumed_samples: 2208 | val_loss: 8.654\n",
      "Training epoch 0, iteration 276/499 | lr: 0.000387 | global_batch_size: 8 | global_step: 276 | reduced_train_loss: 8.533 | consumed_samples: 2216 | val_loss: 8.654\n",
      "Training epoch 0, iteration 277/499 | lr: 0.0003838 | global_batch_size: 8 | global_step: 277 | reduced_train_loss: 8.527 | consumed_samples: 2224 | val_loss: 8.654\n",
      "Training epoch 0, iteration 278/499 | lr: 0.0003806 | global_batch_size: 8 | global_step: 278 | reduced_train_loss: 8.584 | consumed_samples: 2232 | val_loss: 8.654\n",
      "Training epoch 0, iteration 279/499 | lr: 0.0003774 | global_batch_size: 8 | global_step: 279 | reduced_train_loss: 8.218 | consumed_samples: 2240 | val_loss: 8.654\n",
      "Training epoch 0, iteration 280/499 | lr: 0.0003742 | global_batch_size: 8 | global_step: 280 | reduced_train_loss: 8.51 | consumed_samples: 2248 | val_loss: 8.654\n",
      "Training epoch 0, iteration 281/499 | lr: 0.000371 | global_batch_size: 8 | global_step: 281 | reduced_train_loss: 8.493 | consumed_samples: 2256 | val_loss: 8.654\n",
      "Training epoch 0, iteration 282/499 | lr: 0.0003679 | global_batch_size: 8 | global_step: 282 | reduced_train_loss: 8.321 | consumed_samples: 2264 | val_loss: 8.654\n",
      "Training epoch 0, iteration 283/499 | lr: 0.0003647 | global_batch_size: 8 | global_step: 283 | reduced_train_loss: 8.384 | consumed_samples: 2272 | val_loss: 8.654\n",
      "Training epoch 0, iteration 284/499 | lr: 0.0003615 | global_batch_size: 8 | global_step: 284 | reduced_train_loss: 8.444 | consumed_samples: 2280 | val_loss: 8.654\n",
      "Training epoch 0, iteration 285/499 | lr: 0.0003583 | global_batch_size: 8 | global_step: 285 | reduced_train_loss: 8.281 | consumed_samples: 2288 | val_loss: 8.654\n",
      "Training epoch 0, iteration 286/499 | lr: 0.0003552 | global_batch_size: 8 | global_step: 286 | reduced_train_loss: 8.313 | consumed_samples: 2296 | val_loss: 8.654\n",
      "Training epoch 0, iteration 287/499 | lr: 0.000352 | global_batch_size: 8 | global_step: 287 | reduced_train_loss: 8.613 | consumed_samples: 2304 | val_loss: 8.654\n",
      "Training epoch 0, iteration 288/499 | lr: 0.0003489 | global_batch_size: 8 | global_step: 288 | reduced_train_loss: 8.372 | consumed_samples: 2312 | val_loss: 8.654\n",
      "Training epoch 0, iteration 289/499 | lr: 0.0003458 | global_batch_size: 8 | global_step: 289 | reduced_train_loss: 8.255 | consumed_samples: 2320 | val_loss: 8.654\n",
      "Training epoch 0, iteration 290/499 | lr: 0.0003426 | global_batch_size: 8 | global_step: 290 | reduced_train_loss: 8.396 | consumed_samples: 2328 | val_loss: 8.654\n",
      "Training epoch 0, iteration 291/499 | lr: 0.0003395 | global_batch_size: 8 | global_step: 291 | reduced_train_loss: 8.399 | consumed_samples: 2336 | val_loss: 8.654\n",
      "Training epoch 0, iteration 292/499 | lr: 0.0003364 | global_batch_size: 8 | global_step: 292 | reduced_train_loss: 8.244 | consumed_samples: 2344 | val_loss: 8.654\n",
      "Training epoch 0, iteration 293/499 | lr: 0.0003333 | global_batch_size: 8 | global_step: 293 | reduced_train_loss: 8.398 | consumed_samples: 2352 | val_loss: 8.654\n",
      "Training epoch 0, iteration 294/499 | lr: 0.0003302 | global_batch_size: 8 | global_step: 294 | reduced_train_loss: 8.253 | consumed_samples: 2360 | val_loss: 8.654\n",
      "Training epoch 0, iteration 295/499 | lr: 0.0003271 | global_batch_size: 8 | global_step: 295 | reduced_train_loss: 8.443 | consumed_samples: 2368 | val_loss: 8.654\n",
      "Training epoch 0, iteration 296/499 | lr: 0.000324 | global_batch_size: 8 | global_step: 296 | reduced_train_loss: 8.384 | consumed_samples: 2376 | val_loss: 8.654\n",
      "Training epoch 0, iteration 297/499 | lr: 0.0003209 | global_batch_size: 8 | global_step: 297 | reduced_train_loss: 8.369 | consumed_samples: 2384 | val_loss: 8.654\n",
      "Training epoch 0, iteration 298/499 | lr: 0.0003179 | global_batch_size: 8 | global_step: 298 | reduced_train_loss: 8.297 | consumed_samples: 2392 | val_loss: 8.654\n",
      "Training epoch 0, iteration 299/499 | lr: 0.0003148 | global_batch_size: 8 | global_step: 299 | reduced_train_loss: 8.311 | consumed_samples: 2400 | val_loss: 8.654\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: Epoch 0, global step 299: 'reduced_train_loss' reached 8.31067 (best 8.31067), saving model to '/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.65-step=299-consumed_samples=2400.0.ckpt' as top 2\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/transformer/transformer_layer.py:339: UserWarning: TransformerLayer._get_layer_offset is deprecated.Please use get_transformer_layer_offset instead.\n",
      "  warnings.warn(\n",
      "\n",
      "[NeMo I 2025-03-11 20:31:40 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 299 : Start time: 1741725100.457s : Save duration: 0.051s\n",
      "[NeMo I 2025-03-11 20:31:43 nemo_logging:393] Scheduled async checkpoint save for /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.65-step=299-consumed_samples=2400.0.ckpt\n",
      "[NeMo I 2025-03-11 20:31:44 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 299 : Start time: 1741725103.571s : Save duration: 0.453s\n",
      "[NeMo I 2025-03-11 20:31:46 nemo_logging:393] Scheduled async checkpoint save for /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.65-step=299-consumed_samples=2400.0-last.ckpt\n",
      "[NeMo I 2025-03-11 20:31:47 nemo_logging:393] Successfully saved checkpoint from iteration     299 to /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.65-step=299-consumed_samples=2400.0.ckpt\n",
      "[NeMo I 2025-03-11 20:31:47 nemo_logging:393] Async checkpoint save for step 300 (/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.65-step=299-consumed_samples=2400.0.ckpt) finalized successfully.\n",
      "[NeMo I 2025-03-11 20:31:47 nemo_logging:393] Successfully saved checkpoint from iteration     299 to /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.65-step=299-consumed_samples=2400.0-last.ckpt\n",
      "[NeMo I 2025-03-11 20:31:47 nemo_logging:393] Async checkpoint save for step 300 (/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.65-step=299-consumed_samples=2400.0-last.ckpt) finalized successfully.\n",
      "[NeMo I 2025-03-11 20:31:47 nemo_logging:393] Async finalization time took 0.101 s\n",
      "Validation: iteration 1/2\n",
      "Validation: iteration 2/2\n",
      "Validation: iteration 3/2\n",
      "Validation: iteration 4/2\n",
      "Validation: iteration 5/2\n",
      "Validation: iteration 6/2\n",
      "Validation: iteration 7/2\n",
      "Validation: iteration 8/2\n",
      "Training epoch 0, iteration 300/499 | lr: 0.0003118 | global_batch_size: 8 | global_step: 300 | reduced_train_loss: 8.597 | consumed_samples: 2408 | val_loss: 8.409\n",
      "Training epoch 0, iteration 301/499 | lr: 0.0003087 | global_batch_size: 8 | global_step: 301 | reduced_train_loss: 8.3 | consumed_samples: 2416 | val_loss: 8.409\n",
      "Training epoch 0, iteration 302/499 | lr: 0.0003057 | global_batch_size: 8 | global_step: 302 | reduced_train_loss: 8.272 | consumed_samples: 2424 | val_loss: 8.409\n",
      "Training epoch 0, iteration 303/499 | lr: 0.0003027 | global_batch_size: 8 | global_step: 303 | reduced_train_loss: 8.361 | consumed_samples: 2432 | val_loss: 8.409\n",
      "Training epoch 0, iteration 304/499 | lr: 0.0002996 | global_batch_size: 8 | global_step: 304 | reduced_train_loss: 8.432 | consumed_samples: 2440 | val_loss: 8.409\n",
      "Training epoch 0, iteration 305/499 | lr: 0.0002966 | global_batch_size: 8 | global_step: 305 | reduced_train_loss: 8.315 | consumed_samples: 2448 | val_loss: 8.409\n",
      "Training epoch 0, iteration 306/499 | lr: 0.0002936 | global_batch_size: 8 | global_step: 306 | reduced_train_loss: 8.224 | consumed_samples: 2456 | val_loss: 8.409\n",
      "Training epoch 0, iteration 307/499 | lr: 0.0002907 | global_batch_size: 8 | global_step: 307 | reduced_train_loss: 8.461 | consumed_samples: 2464 | val_loss: 8.409\n",
      "Training epoch 0, iteration 308/499 | lr: 0.0002877 | global_batch_size: 8 | global_step: 308 | reduced_train_loss: 8.279 | consumed_samples: 2472 | val_loss: 8.409\n",
      "Training epoch 0, iteration 309/499 | lr: 0.0002847 | global_batch_size: 8 | global_step: 309 | reduced_train_loss: 8.054 | consumed_samples: 2480 | val_loss: 8.409\n",
      "Training epoch 0, iteration 310/499 | lr: 0.0002817 | global_batch_size: 8 | global_step: 310 | reduced_train_loss: 8.389 | consumed_samples: 2488 | val_loss: 8.409\n",
      "Training epoch 0, iteration 311/499 | lr: 0.0002788 | global_batch_size: 8 | global_step: 311 | reduced_train_loss: 8.42 | consumed_samples: 2496 | val_loss: 8.409\n",
      "Training epoch 0, iteration 312/499 | lr: 0.0002759 | global_batch_size: 8 | global_step: 312 | reduced_train_loss: 8.33 | consumed_samples: 2504 | val_loss: 8.409\n",
      "Training epoch 0, iteration 313/499 | lr: 0.0002729 | global_batch_size: 8 | global_step: 313 | reduced_train_loss: 8.386 | consumed_samples: 2512 | val_loss: 8.409\n",
      "Training epoch 0, iteration 314/499 | lr: 0.00027 | global_batch_size: 8 | global_step: 314 | reduced_train_loss: 8.466 | consumed_samples: 2520 | val_loss: 8.409\n",
      "Training epoch 0, iteration 315/499 | lr: 0.0002671 | global_batch_size: 8 | global_step: 315 | reduced_train_loss: 8.307 | consumed_samples: 2528 | val_loss: 8.409\n",
      "Training epoch 0, iteration 316/499 | lr: 0.0002642 | global_batch_size: 8 | global_step: 316 | reduced_train_loss: 8.371 | consumed_samples: 2536 | val_loss: 8.409\n",
      "Training epoch 0, iteration 317/499 | lr: 0.0002613 | global_batch_size: 8 | global_step: 317 | reduced_train_loss: 8.423 | consumed_samples: 2544 | val_loss: 8.409\n",
      "Training epoch 0, iteration 318/499 | lr: 0.0002585 | global_batch_size: 8 | global_step: 318 | reduced_train_loss: 8.183 | consumed_samples: 2552 | val_loss: 8.409\n",
      "Training epoch 0, iteration 319/499 | lr: 0.0002556 | global_batch_size: 8 | global_step: 319 | reduced_train_loss: 8.188 | consumed_samples: 2560 | val_loss: 8.409\n",
      "Training epoch 0, iteration 320/499 | lr: 0.0002527 | global_batch_size: 8 | global_step: 320 | reduced_train_loss: 8.702 | consumed_samples: 2568 | val_loss: 8.409\n",
      "Training epoch 0, iteration 321/499 | lr: 0.0002499 | global_batch_size: 8 | global_step: 321 | reduced_train_loss: 8.393 | consumed_samples: 2576 | val_loss: 8.409\n",
      "Training epoch 0, iteration 322/499 | lr: 0.0002471 | global_batch_size: 8 | global_step: 322 | reduced_train_loss: 8.427 | consumed_samples: 2584 | val_loss: 8.409\n",
      "Training epoch 0, iteration 323/499 | lr: 0.0002443 | global_batch_size: 8 | global_step: 323 | reduced_train_loss: 8.294 | consumed_samples: 2592 | val_loss: 8.409\n",
      "Training epoch 0, iteration 324/499 | lr: 0.0002414 | global_batch_size: 8 | global_step: 324 | reduced_train_loss: 8.501 | consumed_samples: 2600 | val_loss: 8.409\n",
      "Training epoch 0, iteration 325/499 | lr: 0.0002386 | global_batch_size: 8 | global_step: 325 | reduced_train_loss: 8.317 | consumed_samples: 2608 | val_loss: 8.409\n",
      "Training epoch 0, iteration 326/499 | lr: 0.0002359 | global_batch_size: 8 | global_step: 326 | reduced_train_loss: 8.396 | consumed_samples: 2616 | val_loss: 8.409\n",
      "Training epoch 0, iteration 327/499 | lr: 0.0002331 | global_batch_size: 8 | global_step: 327 | reduced_train_loss: 8.346 | consumed_samples: 2624 | val_loss: 8.409\n",
      "Training epoch 0, iteration 328/499 | lr: 0.0002303 | global_batch_size: 8 | global_step: 328 | reduced_train_loss: 8.372 | consumed_samples: 2632 | val_loss: 8.409\n",
      "Training epoch 0, iteration 329/499 | lr: 0.0002276 | global_batch_size: 8 | global_step: 329 | reduced_train_loss: 8.284 | consumed_samples: 2640 | val_loss: 8.409\n",
      "Training epoch 0, iteration 330/499 | lr: 0.0002249 | global_batch_size: 8 | global_step: 330 | reduced_train_loss: 8.383 | consumed_samples: 2648 | val_loss: 8.409\n",
      "Training epoch 0, iteration 331/499 | lr: 0.0002221 | global_batch_size: 8 | global_step: 331 | reduced_train_loss: 8.438 | consumed_samples: 2656 | val_loss: 8.409\n",
      "Training epoch 0, iteration 332/499 | lr: 0.0002194 | global_batch_size: 8 | global_step: 332 | reduced_train_loss: 8.346 | consumed_samples: 2664 | val_loss: 8.409\n",
      "Training epoch 0, iteration 333/499 | lr: 0.0002167 | global_batch_size: 8 | global_step: 333 | reduced_train_loss: 8.113 | consumed_samples: 2672 | val_loss: 8.409\n",
      "Training epoch 0, iteration 334/499 | lr: 0.000214 | global_batch_size: 8 | global_step: 334 | reduced_train_loss: 8.291 | consumed_samples: 2680 | val_loss: 8.409\n",
      "Training epoch 0, iteration 335/499 | lr: 0.0002114 | global_batch_size: 8 | global_step: 335 | reduced_train_loss: 8.24 | consumed_samples: 2688 | val_loss: 8.409\n",
      "Training epoch 0, iteration 336/499 | lr: 0.0002087 | global_batch_size: 8 | global_step: 336 | reduced_train_loss: 8.657 | consumed_samples: 2696 | val_loss: 8.409\n",
      "Training epoch 0, iteration 337/499 | lr: 0.0002061 | global_batch_size: 8 | global_step: 337 | reduced_train_loss: 8.329 | consumed_samples: 2704 | val_loss: 8.409\n",
      "Training epoch 0, iteration 338/499 | lr: 0.0002034 | global_batch_size: 8 | global_step: 338 | reduced_train_loss: 8.128 | consumed_samples: 2712 | val_loss: 8.409\n",
      "Training epoch 0, iteration 339/499 | lr: 0.0002008 | global_batch_size: 8 | global_step: 339 | reduced_train_loss: 8.335 | consumed_samples: 2720 | val_loss: 8.409\n",
      "Training epoch 0, iteration 340/499 | lr: 0.0001982 | global_batch_size: 8 | global_step: 340 | reduced_train_loss: 8.406 | consumed_samples: 2728 | val_loss: 8.409\n",
      "Training epoch 0, iteration 341/499 | lr: 0.0001956 | global_batch_size: 8 | global_step: 341 | reduced_train_loss: 8.507 | consumed_samples: 2736 | val_loss: 8.409\n",
      "Training epoch 0, iteration 342/499 | lr: 0.0001931 | global_batch_size: 8 | global_step: 342 | reduced_train_loss: 8.472 | consumed_samples: 2744 | val_loss: 8.409\n",
      "Training epoch 0, iteration 343/499 | lr: 0.0001905 | global_batch_size: 8 | global_step: 343 | reduced_train_loss: 8.335 | consumed_samples: 2752 | val_loss: 8.409\n",
      "Training epoch 0, iteration 344/499 | lr: 0.0001879 | global_batch_size: 8 | global_step: 344 | reduced_train_loss: 8.267 | consumed_samples: 2760 | val_loss: 8.409\n",
      "Training epoch 0, iteration 345/499 | lr: 0.0001854 | global_batch_size: 8 | global_step: 345 | reduced_train_loss: 8.43 | consumed_samples: 2768 | val_loss: 8.409\n",
      "Training epoch 0, iteration 346/499 | lr: 0.0001829 | global_batch_size: 8 | global_step: 346 | reduced_train_loss: 8.418 | consumed_samples: 2776 | val_loss: 8.409\n",
      "Training epoch 0, iteration 347/499 | lr: 0.0001804 | global_batch_size: 8 | global_step: 347 | reduced_train_loss: 8.476 | consumed_samples: 2784 | val_loss: 8.409\n",
      "Training epoch 0, iteration 348/499 | lr: 0.0001779 | global_batch_size: 8 | global_step: 348 | reduced_train_loss: 8.342 | consumed_samples: 2792 | val_loss: 8.409\n",
      "Training epoch 0, iteration 349/499 | lr: 0.0001754 | global_batch_size: 8 | global_step: 349 | reduced_train_loss: 8.421 | consumed_samples: 2800 | val_loss: 8.409\n",
      "Training epoch 0, iteration 350/499 | lr: 0.000173 | global_batch_size: 8 | global_step: 350 | reduced_train_loss: 8.473 | consumed_samples: 2808 | val_loss: 8.409\n",
      "Training epoch 0, iteration 351/499 | lr: 0.0001705 | global_batch_size: 8 | global_step: 351 | reduced_train_loss: 8.392 | consumed_samples: 2816 | val_loss: 8.409\n",
      "Training epoch 0, iteration 352/499 | lr: 0.0001681 | global_batch_size: 8 | global_step: 352 | reduced_train_loss: 8.21 | consumed_samples: 2824 | val_loss: 8.409\n",
      "Training epoch 0, iteration 353/499 | lr: 0.0001657 | global_batch_size: 8 | global_step: 353 | reduced_train_loss: 8.273 | consumed_samples: 2832 | val_loss: 8.409\n",
      "Training epoch 0, iteration 354/499 | lr: 0.0001633 | global_batch_size: 8 | global_step: 354 | reduced_train_loss: 8.325 | consumed_samples: 2840 | val_loss: 8.409\n",
      "Training epoch 0, iteration 355/499 | lr: 0.0001609 | global_batch_size: 8 | global_step: 355 | reduced_train_loss: 8.464 | consumed_samples: 2848 | val_loss: 8.409\n",
      "Training epoch 0, iteration 356/499 | lr: 0.0001585 | global_batch_size: 8 | global_step: 356 | reduced_train_loss: 8.47 | consumed_samples: 2856 | val_loss: 8.409\n",
      "Training epoch 0, iteration 357/499 | lr: 0.0001562 | global_batch_size: 8 | global_step: 357 | reduced_train_loss: 8.318 | consumed_samples: 2864 | val_loss: 8.409\n",
      "Training epoch 0, iteration 358/499 | lr: 0.0001538 | global_batch_size: 8 | global_step: 358 | reduced_train_loss: 8.282 | consumed_samples: 2872 | val_loss: 8.409\n",
      "Training epoch 0, iteration 359/499 | lr: 0.0001515 | global_batch_size: 8 | global_step: 359 | reduced_train_loss: 8.137 | consumed_samples: 2880 | val_loss: 8.409\n",
      "Training epoch 0, iteration 360/499 | lr: 0.0001492 | global_batch_size: 8 | global_step: 360 | reduced_train_loss: 8.435 | consumed_samples: 2888 | val_loss: 8.409\n",
      "Training epoch 0, iteration 361/499 | lr: 0.0001469 | global_batch_size: 8 | global_step: 361 | reduced_train_loss: 8.139 | consumed_samples: 2896 | val_loss: 8.409\n",
      "Training epoch 0, iteration 362/499 | lr: 0.0001446 | global_batch_size: 8 | global_step: 362 | reduced_train_loss: 8.237 | consumed_samples: 2904 | val_loss: 8.409\n",
      "Training epoch 0, iteration 363/499 | lr: 0.0001424 | global_batch_size: 8 | global_step: 363 | reduced_train_loss: 8.218 | consumed_samples: 2912 | val_loss: 8.409\n",
      "Training epoch 0, iteration 364/499 | lr: 0.0001401 | global_batch_size: 8 | global_step: 364 | reduced_train_loss: 8.326 | consumed_samples: 2920 | val_loss: 8.409\n",
      "Training epoch 0, iteration 365/499 | lr: 0.0001379 | global_batch_size: 8 | global_step: 365 | reduced_train_loss: 8.404 | consumed_samples: 2928 | val_loss: 8.409\n",
      "Training epoch 0, iteration 366/499 | lr: 0.0001357 | global_batch_size: 8 | global_step: 366 | reduced_train_loss: 8.402 | consumed_samples: 2936 | val_loss: 8.409\n",
      "Training epoch 0, iteration 367/499 | lr: 0.0001335 | global_batch_size: 8 | global_step: 367 | reduced_train_loss: 8.212 | consumed_samples: 2944 | val_loss: 8.409\n",
      "Training epoch 0, iteration 368/499 | lr: 0.0001313 | global_batch_size: 8 | global_step: 368 | reduced_train_loss: 8.521 | consumed_samples: 2952 | val_loss: 8.409\n",
      "Training epoch 0, iteration 369/499 | lr: 0.0001291 | global_batch_size: 8 | global_step: 369 | reduced_train_loss: 8.346 | consumed_samples: 2960 | val_loss: 8.409\n",
      "Training epoch 0, iteration 370/499 | lr: 0.000127 | global_batch_size: 8 | global_step: 370 | reduced_train_loss: 8.482 | consumed_samples: 2968 | val_loss: 8.409\n",
      "Training epoch 0, iteration 371/499 | lr: 0.0001249 | global_batch_size: 8 | global_step: 371 | reduced_train_loss: 8.278 | consumed_samples: 2976 | val_loss: 8.409\n",
      "Training epoch 0, iteration 372/499 | lr: 0.0001228 | global_batch_size: 8 | global_step: 372 | reduced_train_loss: 8.106 | consumed_samples: 2984 | val_loss: 8.409\n",
      "Training epoch 0, iteration 373/499 | lr: 0.0001207 | global_batch_size: 8 | global_step: 373 | reduced_train_loss: 8.291 | consumed_samples: 2992 | val_loss: 8.409\n",
      "Training epoch 0, iteration 374/499 | lr: 0.0001186 | global_batch_size: 8 | global_step: 374 | reduced_train_loss: 8.508 | consumed_samples: 3000 | val_loss: 8.409\n",
      "Training epoch 0, iteration 375/499 | lr: 0.0001165 | global_batch_size: 8 | global_step: 375 | reduced_train_loss: 8.166 | consumed_samples: 3008 | val_loss: 8.409\n",
      "Training epoch 0, iteration 376/499 | lr: 0.0001145 | global_batch_size: 8 | global_step: 376 | reduced_train_loss: 8.251 | consumed_samples: 3016 | val_loss: 8.409\n",
      "Training epoch 0, iteration 377/499 | lr: 0.0001125 | global_batch_size: 8 | global_step: 377 | reduced_train_loss: 8.247 | consumed_samples: 3024 | val_loss: 8.409\n",
      "Training epoch 0, iteration 378/499 | lr: 0.0001105 | global_batch_size: 8 | global_step: 378 | reduced_train_loss: 8.389 | consumed_samples: 3032 | val_loss: 8.409\n",
      "Training epoch 0, iteration 379/499 | lr: 0.0001085 | global_batch_size: 8 | global_step: 379 | reduced_train_loss: 8.232 | consumed_samples: 3040 | val_loss: 8.409\n",
      "Training epoch 0, iteration 380/499 | lr: 0.0001065 | global_batch_size: 8 | global_step: 380 | reduced_train_loss: 8.426 | consumed_samples: 3048 | val_loss: 8.409\n",
      "Training epoch 0, iteration 381/499 | lr: 0.0001045 | global_batch_size: 8 | global_step: 381 | reduced_train_loss: 8.203 | consumed_samples: 3056 | val_loss: 8.409\n",
      "Training epoch 0, iteration 382/499 | lr: 0.0001026 | global_batch_size: 8 | global_step: 382 | reduced_train_loss: 8.41 | consumed_samples: 3064 | val_loss: 8.409\n",
      "Training epoch 0, iteration 383/499 | lr: 0.0001007 | global_batch_size: 8 | global_step: 383 | reduced_train_loss: 8.245 | consumed_samples: 3072 | val_loss: 8.409\n",
      "Training epoch 0, iteration 384/499 | lr: 9.878e-05 | global_batch_size: 8 | global_step: 384 | reduced_train_loss: 8.262 | consumed_samples: 3080 | val_loss: 8.409\n",
      "Training epoch 0, iteration 385/499 | lr: 9.69e-05 | global_batch_size: 8 | global_step: 385 | reduced_train_loss: 8.584 | consumed_samples: 3088 | val_loss: 8.409\n",
      "Training epoch 0, iteration 386/499 | lr: 9.504e-05 | global_batch_size: 8 | global_step: 386 | reduced_train_loss: 8.3 | consumed_samples: 3096 | val_loss: 8.409\n",
      "Training epoch 0, iteration 387/499 | lr: 9.319e-05 | global_batch_size: 8 | global_step: 387 | reduced_train_loss: 8.302 | consumed_samples: 3104 | val_loss: 8.409\n",
      "Training epoch 0, iteration 388/499 | lr: 9.137e-05 | global_batch_size: 8 | global_step: 388 | reduced_train_loss: 8.218 | consumed_samples: 3112 | val_loss: 8.409\n",
      "Training epoch 0, iteration 389/499 | lr: 8.956e-05 | global_batch_size: 8 | global_step: 389 | reduced_train_loss: 8.151 | consumed_samples: 3120 | val_loss: 8.409\n",
      "Training epoch 0, iteration 390/499 | lr: 8.777e-05 | global_batch_size: 8 | global_step: 390 | reduced_train_loss: 8.313 | consumed_samples: 3128 | val_loss: 8.409\n",
      "Training epoch 0, iteration 391/499 | lr: 8.6e-05 | global_batch_size: 8 | global_step: 391 | reduced_train_loss: 8.469 | consumed_samples: 3136 | val_loss: 8.409\n",
      "Training epoch 0, iteration 392/499 | lr: 8.425e-05 | global_batch_size: 8 | global_step: 392 | reduced_train_loss: 8.208 | consumed_samples: 3144 | val_loss: 8.409\n",
      "Training epoch 0, iteration 393/499 | lr: 8.251e-05 | global_batch_size: 8 | global_step: 393 | reduced_train_loss: 8.206 | consumed_samples: 3152 | val_loss: 8.409\n",
      "Training epoch 0, iteration 394/499 | lr: 8.08e-05 | global_batch_size: 8 | global_step: 394 | reduced_train_loss: 8.124 | consumed_samples: 3160 | val_loss: 8.409\n",
      "Training epoch 0, iteration 395/499 | lr: 7.91e-05 | global_batch_size: 8 | global_step: 395 | reduced_train_loss: 8.241 | consumed_samples: 3168 | val_loss: 8.409\n",
      "Training epoch 0, iteration 396/499 | lr: 7.742e-05 | global_batch_size: 8 | global_step: 396 | reduced_train_loss: 8.457 | consumed_samples: 3176 | val_loss: 8.409\n",
      "Training epoch 0, iteration 397/499 | lr: 7.577e-05 | global_batch_size: 8 | global_step: 397 | reduced_train_loss: 8.335 | consumed_samples: 3184 | val_loss: 8.409\n",
      "Training epoch 0, iteration 398/499 | lr: 7.413e-05 | global_batch_size: 8 | global_step: 398 | reduced_train_loss: 8.288 | consumed_samples: 3192 | val_loss: 8.409\n",
      "Training epoch 0, iteration 399/499 | lr: 7.251e-05 | global_batch_size: 8 | global_step: 399 | reduced_train_loss: 8.437 | consumed_samples: 3200 | val_loss: 8.409\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: Epoch 0, global step 399: 'reduced_train_loss' reached 8.43677 (best 8.31067), saving model to '/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.41-step=399-consumed_samples=3200.0.ckpt' as top 2\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/transformer/transformer_layer.py:339: UserWarning: TransformerLayer._get_layer_offset is deprecated.Please use get_transformer_layer_offset instead.\n",
      "  warnings.warn(\n",
      "\n",
      "[NeMo I 2025-03-11 20:31:55 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 399 : Start time: 1741725115.940s : Save duration: 0.051s\n",
      "[NeMo I 2025-03-11 20:31:59 nemo_logging:393] Scheduled async checkpoint save for /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.41-step=399-consumed_samples=3200.0.ckpt\n",
      "[NeMo I 2025-03-11 20:31:59 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 399 : Start time: 1741725119.044s : Save duration: 0.051s\n",
      "[NeMo I 2025-03-11 20:32:02 nemo_logging:393] Scheduled async checkpoint save for /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.41-step=399-consumed_samples=3200.0-last.ckpt\n",
      "[NeMo I 2025-03-11 20:32:02 nemo_logging:393] Successfully saved checkpoint from iteration     399 to /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.41-step=399-consumed_samples=3200.0.ckpt\n",
      "[NeMo I 2025-03-11 20:32:02 nemo_logging:393] Async checkpoint save for step 400 (/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.41-step=399-consumed_samples=3200.0.ckpt) finalized successfully.\n",
      "[NeMo I 2025-03-11 20:32:02 nemo_logging:393] Successfully saved checkpoint from iteration     399 to /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.41-step=399-consumed_samples=3200.0-last.ckpt\n",
      "[NeMo I 2025-03-11 20:32:02 nemo_logging:393] Async checkpoint save for step 400 (/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.41-step=399-consumed_samples=3200.0-last.ckpt) finalized successfully.\n",
      "[NeMo I 2025-03-11 20:32:02 nemo_logging:393] Async finalization time took 0.096 s\n",
      "Validation: iteration 1/2\n",
      "Validation: iteration 2/2\n",
      "Validation: iteration 3/2\n",
      "Validation: iteration 4/2\n",
      "Validation: iteration 5/2\n",
      "Validation: iteration 6/2\n",
      "Validation: iteration 7/2\n",
      "Validation: iteration 8/2\n",
      "Training epoch 0, iteration 400/499 | lr: 7.091e-05 | global_batch_size: 8 | global_step: 400 | reduced_train_loss: 8.163 | consumed_samples: 3208 | val_loss: 8.28\n",
      "Training epoch 0, iteration 401/499 | lr: 6.933e-05 | global_batch_size: 8 | global_step: 401 | reduced_train_loss: 8.448 | consumed_samples: 3216 | val_loss: 8.28\n",
      "Training epoch 0, iteration 402/499 | lr: 6.777e-05 | global_batch_size: 8 | global_step: 402 | reduced_train_loss: 8.387 | consumed_samples: 3224 | val_loss: 8.28\n",
      "Training epoch 0, iteration 403/499 | lr: 6.623e-05 | global_batch_size: 8 | global_step: 403 | reduced_train_loss: 8.415 | consumed_samples: 3232 | val_loss: 8.28\n",
      "Training epoch 0, iteration 404/499 | lr: 6.471e-05 | global_batch_size: 8 | global_step: 404 | reduced_train_loss: 8.102 | consumed_samples: 3240 | val_loss: 8.28\n",
      "Training epoch 0, iteration 405/499 | lr: 6.32e-05 | global_batch_size: 8 | global_step: 405 | reduced_train_loss: 8.257 | consumed_samples: 3248 | val_loss: 8.28\n",
      "Training epoch 0, iteration 406/499 | lr: 6.172e-05 | global_batch_size: 8 | global_step: 406 | reduced_train_loss: 8.301 | consumed_samples: 3256 | val_loss: 8.28\n",
      "Training epoch 0, iteration 407/499 | lr: 6.026e-05 | global_batch_size: 8 | global_step: 407 | reduced_train_loss: 8.347 | consumed_samples: 3264 | val_loss: 8.28\n",
      "Training epoch 0, iteration 408/499 | lr: 5.882e-05 | global_batch_size: 8 | global_step: 408 | reduced_train_loss: 8.335 | consumed_samples: 3272 | val_loss: 8.28\n",
      "Training epoch 0, iteration 409/499 | lr: 5.739e-05 | global_batch_size: 8 | global_step: 409 | reduced_train_loss: 8.205 | consumed_samples: 3280 | val_loss: 8.28\n",
      "Training epoch 0, iteration 410/499 | lr: 5.599e-05 | global_batch_size: 8 | global_step: 410 | reduced_train_loss: 8.378 | consumed_samples: 3288 | val_loss: 8.28\n",
      "Training epoch 0, iteration 411/499 | lr: 5.461e-05 | global_batch_size: 8 | global_step: 411 | reduced_train_loss: 8.424 | consumed_samples: 3296 | val_loss: 8.28\n",
      "Training epoch 0, iteration 412/499 | lr: 5.324e-05 | global_batch_size: 8 | global_step: 412 | reduced_train_loss: 8.135 | consumed_samples: 3304 | val_loss: 8.28\n",
      "Training epoch 0, iteration 413/499 | lr: 5.19e-05 | global_batch_size: 8 | global_step: 413 | reduced_train_loss: 8.187 | consumed_samples: 3312 | val_loss: 8.28\n",
      "Training epoch 0, iteration 414/499 | lr: 5.058e-05 | global_batch_size: 8 | global_step: 414 | reduced_train_loss: 8.055 | consumed_samples: 3320 | val_loss: 8.28\n",
      "Training epoch 0, iteration 415/499 | lr: 4.928e-05 | global_batch_size: 8 | global_step: 415 | reduced_train_loss: 8.373 | consumed_samples: 3328 | val_loss: 8.28\n",
      "Training epoch 0, iteration 416/499 | lr: 4.8e-05 | global_batch_size: 8 | global_step: 416 | reduced_train_loss: 8.308 | consumed_samples: 3336 | val_loss: 8.28\n",
      "Training epoch 0, iteration 417/499 | lr: 4.674e-05 | global_batch_size: 8 | global_step: 417 | reduced_train_loss: 8.31 | consumed_samples: 3344 | val_loss: 8.28\n",
      "Training epoch 0, iteration 418/499 | lr: 4.55e-05 | global_batch_size: 8 | global_step: 418 | reduced_train_loss: 8.076 | consumed_samples: 3352 | val_loss: 8.28\n",
      "Training epoch 0, iteration 419/499 | lr: 4.428e-05 | global_batch_size: 8 | global_step: 419 | reduced_train_loss: 8.194 | consumed_samples: 3360 | val_loss: 8.28\n",
      "Training epoch 0, iteration 420/499 | lr: 4.308e-05 | global_batch_size: 8 | global_step: 420 | reduced_train_loss: 8.139 | consumed_samples: 3368 | val_loss: 8.28\n",
      "Training epoch 0, iteration 421/499 | lr: 4.19e-05 | global_batch_size: 8 | global_step: 421 | reduced_train_loss: 8.361 | consumed_samples: 3376 | val_loss: 8.28\n",
      "Training epoch 0, iteration 422/499 | lr: 4.074e-05 | global_batch_size: 8 | global_step: 422 | reduced_train_loss: 8.315 | consumed_samples: 3384 | val_loss: 8.28\n",
      "Training epoch 0, iteration 423/499 | lr: 3.96e-05 | global_batch_size: 8 | global_step: 423 | reduced_train_loss: 8.419 | consumed_samples: 3392 | val_loss: 8.28\n",
      "Training epoch 0, iteration 424/499 | lr: 3.848e-05 | global_batch_size: 8 | global_step: 424 | reduced_train_loss: 8.131 | consumed_samples: 3400 | val_loss: 8.28\n",
      "Training epoch 0, iteration 425/499 | lr: 3.739e-05 | global_batch_size: 8 | global_step: 425 | reduced_train_loss: 8.344 | consumed_samples: 3408 | val_loss: 8.28\n",
      "Training epoch 0, iteration 426/499 | lr: 3.631e-05 | global_batch_size: 8 | global_step: 426 | reduced_train_loss: 8.262 | consumed_samples: 3416 | val_loss: 8.28\n",
      "Training epoch 0, iteration 427/499 | lr: 3.526e-05 | global_batch_size: 8 | global_step: 427 | reduced_train_loss: 8.517 | consumed_samples: 3424 | val_loss: 8.28\n",
      "Training epoch 0, iteration 428/499 | lr: 3.423e-05 | global_batch_size: 8 | global_step: 428 | reduced_train_loss: 8.197 | consumed_samples: 3432 | val_loss: 8.28\n",
      "Training epoch 0, iteration 429/499 | lr: 3.322e-05 | global_batch_size: 8 | global_step: 429 | reduced_train_loss: 8.327 | consumed_samples: 3440 | val_loss: 8.28\n",
      "Training epoch 0, iteration 430/499 | lr: 3.222e-05 | global_batch_size: 8 | global_step: 430 | reduced_train_loss: 8.209 | consumed_samples: 3448 | val_loss: 8.28\n",
      "Training epoch 0, iteration 431/499 | lr: 3.125e-05 | global_batch_size: 8 | global_step: 431 | reduced_train_loss: 8.107 | consumed_samples: 3456 | val_loss: 8.28\n",
      "Training epoch 0, iteration 432/499 | lr: 3.031e-05 | global_batch_size: 8 | global_step: 432 | reduced_train_loss: 8.163 | consumed_samples: 3464 | val_loss: 8.28\n",
      "Training epoch 0, iteration 433/499 | lr: 2.938e-05 | global_batch_size: 8 | global_step: 433 | reduced_train_loss: 8.11 | consumed_samples: 3472 | val_loss: 8.28\n",
      "Training epoch 0, iteration 434/499 | lr: 2.847e-05 | global_batch_size: 8 | global_step: 434 | reduced_train_loss: 8.456 | consumed_samples: 3480 | val_loss: 8.28\n",
      "Training epoch 0, iteration 435/499 | lr: 2.759e-05 | global_batch_size: 8 | global_step: 435 | reduced_train_loss: 8.108 | consumed_samples: 3488 | val_loss: 8.28\n",
      "Training epoch 0, iteration 436/499 | lr: 2.672e-05 | global_batch_size: 8 | global_step: 436 | reduced_train_loss: 8.194 | consumed_samples: 3496 | val_loss: 8.28\n",
      "Training epoch 0, iteration 437/499 | lr: 2.588e-05 | global_batch_size: 8 | global_step: 437 | reduced_train_loss: 8.314 | consumed_samples: 3504 | val_loss: 8.28\n",
      "Training epoch 0, iteration 438/499 | lr: 2.506e-05 | global_batch_size: 8 | global_step: 438 | reduced_train_loss: 8.144 | consumed_samples: 3512 | val_loss: 8.28\n",
      "Training epoch 0, iteration 439/499 | lr: 2.426e-05 | global_batch_size: 8 | global_step: 439 | reduced_train_loss: 8.36 | consumed_samples: 3520 | val_loss: 8.28\n",
      "Training epoch 0, iteration 440/499 | lr: 2.348e-05 | global_batch_size: 8 | global_step: 440 | reduced_train_loss: 8.267 | consumed_samples: 3528 | val_loss: 8.28\n",
      "Training epoch 0, iteration 441/499 | lr: 2.273e-05 | global_batch_size: 8 | global_step: 441 | reduced_train_loss: 8.478 | consumed_samples: 3536 | val_loss: 8.28\n",
      "Training epoch 0, iteration 442/499 | lr: 2.199e-05 | global_batch_size: 8 | global_step: 442 | reduced_train_loss: 8.341 | consumed_samples: 3544 | val_loss: 8.28\n",
      "Training epoch 0, iteration 443/499 | lr: 2.128e-05 | global_batch_size: 8 | global_step: 443 | reduced_train_loss: 8.305 | consumed_samples: 3552 | val_loss: 8.28\n",
      "Training epoch 0, iteration 444/499 | lr: 2.059e-05 | global_batch_size: 8 | global_step: 444 | reduced_train_loss: 8.325 | consumed_samples: 3560 | val_loss: 8.28\n",
      "Training epoch 0, iteration 445/499 | lr: 1.992e-05 | global_batch_size: 8 | global_step: 445 | reduced_train_loss: 8.417 | consumed_samples: 3568 | val_loss: 8.28\n",
      "Training epoch 0, iteration 446/499 | lr: 1.927e-05 | global_batch_size: 8 | global_step: 446 | reduced_train_loss: 8.262 | consumed_samples: 3576 | val_loss: 8.28\n",
      "Training epoch 0, iteration 447/499 | lr: 1.864e-05 | global_batch_size: 8 | global_step: 447 | reduced_train_loss: 8.189 | consumed_samples: 3584 | val_loss: 8.28\n",
      "Training epoch 0, iteration 448/499 | lr: 1.804e-05 | global_batch_size: 8 | global_step: 448 | reduced_train_loss: 8.114 | consumed_samples: 3592 | val_loss: 8.28\n",
      "Training epoch 0, iteration 449/499 | lr: 1.746e-05 | global_batch_size: 8 | global_step: 449 | reduced_train_loss: 8.154 | consumed_samples: 3600 | val_loss: 8.28\n",
      "Training epoch 0, iteration 450/499 | lr: 1.69e-05 | global_batch_size: 8 | global_step: 450 | reduced_train_loss: 8.13 | consumed_samples: 3608 | val_loss: 8.28\n",
      "Training epoch 0, iteration 451/499 | lr: 1.636e-05 | global_batch_size: 8 | global_step: 451 | reduced_train_loss: 8.24 | consumed_samples: 3616 | val_loss: 8.28\n",
      "Training epoch 0, iteration 452/499 | lr: 1.584e-05 | global_batch_size: 8 | global_step: 452 | reduced_train_loss: 8.206 | consumed_samples: 3624 | val_loss: 8.28\n",
      "Training epoch 0, iteration 453/499 | lr: 1.534e-05 | global_batch_size: 8 | global_step: 453 | reduced_train_loss: 7.939 | consumed_samples: 3632 | val_loss: 8.28\n",
      "Training epoch 0, iteration 454/499 | lr: 1.487e-05 | global_batch_size: 8 | global_step: 454 | reduced_train_loss: 8.314 | consumed_samples: 3640 | val_loss: 8.28\n",
      "Training epoch 0, iteration 455/499 | lr: 1.442e-05 | global_batch_size: 8 | global_step: 455 | reduced_train_loss: 8.245 | consumed_samples: 3648 | val_loss: 8.28\n",
      "Training epoch 0, iteration 456/499 | lr: 1.399e-05 | global_batch_size: 8 | global_step: 456 | reduced_train_loss: 8.481 | consumed_samples: 3656 | val_loss: 8.28\n",
      "Training epoch 0, iteration 457/499 | lr: 1.358e-05 | global_batch_size: 8 | global_step: 457 | reduced_train_loss: 8.144 | consumed_samples: 3664 | val_loss: 8.28\n",
      "Training epoch 0, iteration 458/499 | lr: 1.319e-05 | global_batch_size: 8 | global_step: 458 | reduced_train_loss: 8.092 | consumed_samples: 3672 | val_loss: 8.28\n",
      "Training epoch 0, iteration 459/499 | lr: 1.283e-05 | global_batch_size: 8 | global_step: 459 | reduced_train_loss: 8.222 | consumed_samples: 3680 | val_loss: 8.28\n",
      "Training epoch 0, iteration 460/499 | lr: 1.249e-05 | global_batch_size: 8 | global_step: 460 | reduced_train_loss: 8.245 | consumed_samples: 3688 | val_loss: 8.28\n",
      "Training epoch 0, iteration 461/499 | lr: 1.217e-05 | global_batch_size: 8 | global_step: 461 | reduced_train_loss: 8.278 | consumed_samples: 3696 | val_loss: 8.28\n",
      "Training epoch 0, iteration 462/499 | lr: 1.187e-05 | global_batch_size: 8 | global_step: 462 | reduced_train_loss: 8.303 | consumed_samples: 3704 | val_loss: 8.28\n",
      "Training epoch 0, iteration 463/499 | lr: 1.159e-05 | global_batch_size: 8 | global_step: 463 | reduced_train_loss: 8.142 | consumed_samples: 3712 | val_loss: 8.28\n",
      "Training epoch 0, iteration 464/499 | lr: 1.134e-05 | global_batch_size: 8 | global_step: 464 | reduced_train_loss: 8.387 | consumed_samples: 3720 | val_loss: 8.28\n",
      "Training epoch 0, iteration 465/499 | lr: 1.111e-05 | global_batch_size: 8 | global_step: 465 | reduced_train_loss: 8.264 | consumed_samples: 3728 | val_loss: 8.28\n",
      "Training epoch 0, iteration 466/499 | lr: 1.09e-05 | global_batch_size: 8 | global_step: 466 | reduced_train_loss: 8.385 | consumed_samples: 3736 | val_loss: 8.28\n",
      "Training epoch 0, iteration 467/499 | lr: 1.071e-05 | global_batch_size: 8 | global_step: 467 | reduced_train_loss: 8.145 | consumed_samples: 3744 | val_loss: 8.28\n",
      "Training epoch 0, iteration 468/499 | lr: 1.054e-05 | global_batch_size: 8 | global_step: 468 | reduced_train_loss: 8.335 | consumed_samples: 3752 | val_loss: 8.28\n",
      "Training epoch 0, iteration 469/499 | lr: 1.04e-05 | global_batch_size: 8 | global_step: 469 | reduced_train_loss: 8.429 | consumed_samples: 3760 | val_loss: 8.28\n",
      "Training epoch 0, iteration 470/499 | lr: 1.028e-05 | global_batch_size: 8 | global_step: 470 | reduced_train_loss: 8.274 | consumed_samples: 3768 | val_loss: 8.28\n",
      "Training epoch 0, iteration 471/499 | lr: 1.018e-05 | global_batch_size: 8 | global_step: 471 | reduced_train_loss: 8.185 | consumed_samples: 3776 | val_loss: 8.28\n",
      "Training epoch 0, iteration 472/499 | lr: 1.01e-05 | global_batch_size: 8 | global_step: 472 | reduced_train_loss: 8.278 | consumed_samples: 3784 | val_loss: 8.28\n",
      "Training epoch 0, iteration 473/499 | lr: 1.004e-05 | global_batch_size: 8 | global_step: 473 | reduced_train_loss: 8.431 | consumed_samples: 3792 | val_loss: 8.28\n",
      "Training epoch 0, iteration 474/499 | lr: 1.001e-05 | global_batch_size: 8 | global_step: 474 | reduced_train_loss: 8.386 | consumed_samples: 3800 | val_loss: 8.28\n",
      "Training epoch 0, iteration 475/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 475 | reduced_train_loss: 8.126 | consumed_samples: 3808 | val_loss: 8.28\n",
      "Training epoch 0, iteration 476/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 476 | reduced_train_loss: 8.338 | consumed_samples: 3816 | val_loss: 8.28\n",
      "Training epoch 0, iteration 477/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 477 | reduced_train_loss: 8.296 | consumed_samples: 3824 | val_loss: 8.28\n",
      "Training epoch 0, iteration 478/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 478 | reduced_train_loss: 8.111 | consumed_samples: 3832 | val_loss: 8.28\n",
      "Training epoch 0, iteration 479/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 479 | reduced_train_loss: 8.277 | consumed_samples: 3840 | val_loss: 8.28\n",
      "Training epoch 0, iteration 480/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 480 | reduced_train_loss: 8.187 | consumed_samples: 3848 | val_loss: 8.28\n",
      "Training epoch 0, iteration 481/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 481 | reduced_train_loss: 8.268 | consumed_samples: 3856 | val_loss: 8.28\n",
      "Training epoch 0, iteration 482/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 482 | reduced_train_loss: 8.208 | consumed_samples: 3864 | val_loss: 8.28\n",
      "Training epoch 0, iteration 483/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 483 | reduced_train_loss: 8.206 | consumed_samples: 3872 | val_loss: 8.28\n",
      "Training epoch 0, iteration 484/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 484 | reduced_train_loss: 8.303 | consumed_samples: 3880 | val_loss: 8.28\n",
      "Training epoch 0, iteration 485/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 485 | reduced_train_loss: 8.281 | consumed_samples: 3888 | val_loss: 8.28\n",
      "Training epoch 0, iteration 486/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 486 | reduced_train_loss: 8.362 | consumed_samples: 3896 | val_loss: 8.28\n",
      "Training epoch 0, iteration 487/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 487 | reduced_train_loss: 8.114 | consumed_samples: 3904 | val_loss: 8.28\n",
      "Training epoch 0, iteration 488/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 488 | reduced_train_loss: 8.362 | consumed_samples: 3912 | val_loss: 8.28\n",
      "Training epoch 0, iteration 489/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 489 | reduced_train_loss: 8.33 | consumed_samples: 3920 | val_loss: 8.28\n",
      "Training epoch 0, iteration 490/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 490 | reduced_train_loss: 8.2 | consumed_samples: 3928 | val_loss: 8.28\n",
      "Training epoch 0, iteration 491/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 491 | reduced_train_loss: 8.397 | consumed_samples: 3936 | val_loss: 8.28\n",
      "Training epoch 0, iteration 492/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 492 | reduced_train_loss: 8.12 | consumed_samples: 3944 | val_loss: 8.28\n",
      "Training epoch 0, iteration 493/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 493 | reduced_train_loss: 8.295 | consumed_samples: 3952 | val_loss: 8.28\n",
      "Training epoch 0, iteration 494/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 494 | reduced_train_loss: 8.39 | consumed_samples: 3960 | val_loss: 8.28\n",
      "Training epoch 0, iteration 495/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 495 | reduced_train_loss: 8.192 | consumed_samples: 3968 | val_loss: 8.28\n",
      "Training epoch 0, iteration 496/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 496 | reduced_train_loss: 8.25 | consumed_samples: 3976 | val_loss: 8.28\n",
      "Training epoch 0, iteration 497/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 497 | reduced_train_loss: 8.08 | consumed_samples: 3984 | val_loss: 8.28\n",
      "Training epoch 0, iteration 498/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 498 | reduced_train_loss: 8.343 | consumed_samples: 3992 | val_loss: 8.28\n",
      "Training epoch 0, iteration 499/499 | lr: 1e-05 | global_batch_size: 8 | global_step: 499 | reduced_train_loss: 8.03 | consumed_samples: 4000 | val_loss: 8.28\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: Epoch 0, global step 499: 'reduced_train_loss' reached 8.02971 (best 8.02971), saving model to '/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0.ckpt' as top 2\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/transformer/transformer_layer.py:339: UserWarning: TransformerLayer._get_layer_offset is deprecated.Please use get_transformer_layer_offset instead.\n",
      "  warnings.warn(\n",
      "\n",
      "[NeMo I 2025-03-11 20:32:11 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 499 : Start time: 1741725131.041s : Save duration: 0.014s\n",
      "[NeMo I 2025-03-11 20:32:14 nemo_logging:393] Scheduled async checkpoint save for /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0.ckpt\n",
      "[NeMo I 2025-03-11 20:32:14 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 499 : Start time: 1741725134.016s : Save duration: 0.013s\n",
      "[NeMo I 2025-03-11 20:32:16 nemo_logging:393] Scheduled async checkpoint save for /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0-last.ckpt\n",
      "[NeMo I 2025-03-11 20:32:17 nemo_logging:393] Successfully saved checkpoint from iteration     499 to /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0.ckpt\n",
      "[NeMo I 2025-03-11 20:32:17 nemo_logging:393] Async checkpoint save for step 500 (/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0.ckpt) finalized successfully.\n",
      "[NeMo I 2025-03-11 20:32:17 nemo_logging:393] Successfully saved checkpoint from iteration     499 to /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0-last.ckpt\n",
      "[NeMo I 2025-03-11 20:32:17 nemo_logging:393] Async checkpoint save for step 500 (/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0-last.ckpt) finalized successfully.\n",
      "[NeMo I 2025-03-11 20:32:17 nemo_logging:393] Async finalization time took 0.090 s\n",
      "Validation: iteration 1/2\n",
      "Validation: iteration 2/2\n",
      "Validation: iteration 3/2\n",
      "Validation: iteration 4/2\n",
      "Validation: iteration 5/2\n",
      "Validation: iteration 6/2\n",
      "Validation: iteration 7/2\n",
      "Validation: iteration 8/2\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: `Trainer.fit` stopped: `max_steps=500` reached.\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /workspace/bionemo2/results/geneformer-10m/wandb/offline-run-20250311_203046-1\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35m../../../../../results/geneformer-10m/wandb/offline-run-20250311_203046-1/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run pretraining using the short recipe\n",
    "!python /workspace/bionemo2/sub-packages/bionemo-geneformer/src/bionemo/geneformer/run/main.py \\\n",
    "--config /workspace/bionemo2/docs/docs/user-guide/examples/bionemo-geneformer/pretrain-recipe-short.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23771e9-0dd6-414e-8cd0-5cd9a9dd4a6b",
   "metadata": {},
   "source": [
    "# Running inference.\n",
    "\n",
    "We can see from the above training job that the model was trained 1000 steps. At the end of training, the experiment manager leaves a message about where the resulting `.ckpt` checkpoint is written. This file is used for finetuning, inference, or training from an existing set of model weights. See the example produced below from our run:\n",
    "\n",
    "```text\n",
    "[NeMo I 2025-03-11 20:32:11 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 499 : Start time: 1741725131.041s : Save duration: 0.014s\n",
    "[NeMo I 2025-03-11 20:32:14 nemo_logging:393] Scheduled async checkpoint save for /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0.ckpt\n",
    "[NeMo I 2025-03-11 20:32:14 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 499 : Start time: 1741725134.016s : Save duration: 0.013s\n",
    "[NeMo I 2025-03-11 20:32:16 nemo_logging:393] Scheduled async checkpoint save for /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0-last.ckpt\n",
    "[NeMo I 2025-03-11 20:32:17 nemo_logging:393] Successfully saved checkpoint from iteration     499 to /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0.ckpt\n",
    "[NeMo I 2025-03-11 20:32:17 nemo_logging:393] Async checkpoint save for step 500 (/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0.ckpt) finalized successfully.\n",
    "[NeMo I 2025-03-11 20:32:17 nemo_logging:393] Successfully saved checkpoint from iteration     499 to /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0-last.ckpt\n",
    "[NeMo I 2025-03-11 20:32:17 nemo_logging:393] Async checkpoint save for step 500 (/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0-last.ckpt) finalized successfully.\n",
    "[NeMo I 2025-03-11 20:32:17 nemo_logging:393] Async finalization time took 0.090 s\n",
    "```\n",
    "\n",
    "We will take the `.ckpt` file logged:\n",
    "`/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0-last`\n",
    "\n",
    "and use this for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b11a330-b8f6-491a-b608-fe47e78f83ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pretrained_nemo_file = '/workspace/bionemo/data/singlecell_tutorial/inference_output/geneformer/2024-05-13_16-53-24/checkpoints/geneformer.nemo'\n",
    "pretrained_checkpoint_path = '/workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0-last'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c70c62ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-11 20:41:44 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[NeMo W 2025-03-11 20:41:48 nemo_logging:405] Tokenizer vocab file: /workspace/bionemo2/.cache/bionemo/d8e3ea569bc43768c24aa651aff77722df202078415528497c22394046b08cc3-singlecell-scdltestdata-20241203.tar.gz.untar/cellxgene_2023-12-15_small_processed_scdl/train/geneformer.vocab already exists. Overwriting...\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] Resource already exists, skipping download: https://huggingface.co/ctheodoris/Geneformer/resolve/main/geneformer/gene_dictionaries_30m/gene_name_id_dict_gc30M.pkl?download=true\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] Resource already exists, skipping download: https://huggingface.co/ctheodoris/Geneformer/resolve/main/geneformer/gene_dictionaries_30m/gene_median_dictionary_gc30M.pkl?download=true\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] *************** Preprocessing Finished ************\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-03-11 20:41:48 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[WARNING  | /workspace/bionemo2/sub-packages/bionemo-llm/src/bionemo/llm/model/config.py]: Loading /workspace/bionemo2/results/geneformer-10m/dev/checkpoints/epoch=0-val_loss=8.28-step=499-consumed_samples=4000.0-last\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/models/bert/bert_layer_specs.py:79: UserWarning: Attribute bert_layer_specs.bert_layer_with_transformer_engine_spec is on a\n",
      "            deprecation track and will be removed in future releases. Please migrate to\n",
      "            bert_layer_specs.get_bert_layer_with_transformer_engine_spec().\n",
      "  warnings.warn(\n",
      "\n",
      "[NeMo I 2025-03-11 20:41:49 nemo_logging:393] Padded vocab_size: 25472, original vocab_size: 25429, dummy tokens: 43.\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/transformer/transformer_layer.py:339: UserWarning: TransformerLayer._get_layer_offset is deprecated.Please use get_transformer_layer_offset instead.\n",
      "  warnings.warn(\n",
      "\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/dist_checkpointing/strategies/torch.py:847: FutureWarning: `load_state_dict` is deprecated and will be removed in future versions. Please use `load` instead.\n",
      "  checkpoint.load_state_dict(\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/torch/distributed/checkpoint/planner_helpers.py:316: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  device = getattr(value, \"device\", None)\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "[NeMo W 2025-03-11 20:41:49 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-03-11 20:41:49 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 10300032\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python /workspace/bionemo2/sub-packages/bionemo-geneformer/src/bionemo/geneformer/scripts/infer_geneformer.py \\\n",
    "    --data-dir {test_tutorial_processed_dir} \\\n",
    "    --checkpoint-path {pretrained_checkpoint_path} \\\n",
    "    --results-path {tutorial_output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c64ebc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 128K\n",
      "drwxr-xr-x 5 jomitchell domain-users 4.0K Mar 11 18:57 ..\n",
      "-rw-r--r-- 1 jomitchell domain-users 118K Mar 11 20:41 predictions__rank_0.pt\n",
      "drwxr-xr-x 2 jomitchell domain-users 4.0K Mar 11 20:41 .\n",
      "-rw-r--r-- 1 jomitchell domain-users 118K Mar 11 20:41 /workspace/bionemo2/data/singlecell_tutorial/inference_output/predictions__rank_0.pt\n"
     ]
    }
   ],
   "source": [
    "!ls -altrh {tutorial_output_dir}/\n",
    "tutorial_output_inference_pickle = f\"{tutorial_output_dir}/predictions__rank_0.pt\"\n",
    "!ls -altrh {tutorial_output_inference_pickle}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b9a425-850d-4027-9160-5e659c163604",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load inference result and cluster with UMAP.\n",
    "Now we will inspect our result. First, we expect there to be one prediction for each cell, we can compare the shape of the anndata object to the predictions produced by our model. After this, we can simply pass our embeddings into umap, and view the result! In this case its a very poorly trained model with very few cells, so keep expectations low!\n",
    "\n",
    "The inference_results .pt file contains one set of hiddens and embeddings for each cell. The hiddens contain the embedding per-token, whereas the embeddings contain the mean embedding for all gene tokens with special tokens (CLS, MASK, etc) removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fade4564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['token_logits', 'binary_logits', 'embeddings'])\n",
      "torch.Size([232, 256])\n",
      "Inference results data type:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Load inference results with torch load\n",
    "import torch\n",
    "inference_results = torch.load(tutorial_output_inference_pickle)\n",
    "print(inference_results.keys())\n",
    "\n",
    "# print(len(inference_results), adata.shape, inference_results[0].keys())\n",
    "print(inference_results['embeddings'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9898a688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(inference_results['embeddings'].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c390680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.shape:  (232, 2)\n",
      "adata_test.obs.shape[0]:  232\n"
     ]
    }
   ],
   "source": [
    "print(\"embedding.shape: \", embedding.shape)\n",
    "print(\"adata_test.obs.shape[0]: \", adata_test.obs.shape[0])\n",
    "assert adata_test.obs.shape[0] == inference_results['embeddings'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ea88b8a-bb3c-4058-93a0-9afb0dfedfa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29198/3842729369.py:11: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for cov, cov_df in results.groupby(covar):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "results = adata_test.obs.copy()\n",
    "results['x'] = embedding[:, 0]\n",
    "results['y'] = embedding[:, 1]\n",
    "\n",
    "covariates = [\"assay\", \"development_stage\", \"dataset_id\", \"sex\"]\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(10,10))\n",
    "\n",
    "for ax,covar in zip(axes.flat, covariates):\n",
    "    for cov, cov_df in results.groupby(covar):\n",
    "        ax.scatter(\n",
    "            cov_df.x,\n",
    "            cov_df.y,\n",
    "            s=3,\n",
    "            alpha=0.75,\n",
    "            label=cov,\n",
    "        )\n",
    "    if len(results[covar].unique()) < 8:\n",
    "        ax.legend()\n",
    "    ax.set_title(f\"Embeddings by {covar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bafb8266-7451-495b-bdae-9bd51c6a214a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['soma_joinid', 'dataset_id', 'assay', 'assay_ontology_term_id',\n",
       "       'cell_type', 'cell_type_ontology_term_id', 'development_stage',\n",
       "       'development_stage_ontology_term_id', 'disease',\n",
       "       'disease_ontology_term_id', 'donor_id', 'is_primary_data',\n",
       "       'self_reported_ethnicity', 'self_reported_ethnicity_ontology_term_id',\n",
       "       'sex', 'sex_ontology_term_id', 'suspension_type', 'tissue',\n",
       "       'tissue_ontology_term_id', 'tissue_general',\n",
       "       'tissue_general_ontology_term_id', 'raw_sum', 'nnz', 'raw_mean_nnz',\n",
       "       'raw_variance_nnz', 'n_measured_vars'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_test.obs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e8d923-faea-487a-90c6-e59a6e99c41a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
